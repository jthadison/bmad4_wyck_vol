# Story 3.8: TradingRangeDetector Module Integration

## Status
Done
Ready for Development

## Story

**As a** pattern detection engine,
**I want** a unified TradingRangeDetector that orchestrates pivot detection, clustering, quality scoring, level calculation, and zone mapping,
**so that** pattern detectors (Epics 4-6) have a single, performant interface to access complete trading range analysis with all levels and zones.

## Acceptance Criteria

1. Class: `TradingRangeDetector` with method `detect_ranges(bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]`
2. TradingRange dataclass contains: creek, ice, jump, midpoint, quality_score, duration, supply_zones, demand_zones
3. Batch processing: detect all ranges in 500-bar sequence
4. Overlapping range handling: newer ranges take precedence, older ranges archived
5. Range lifecycle: FORMING → ACTIVE → BREAKOUT → COMPLETED
6. Cache detected ranges to avoid recomputation
7. Logging: info log when new range detected with key metrics
8. Unit test: end-to-end range detection with synthetic data
9. Integration test: detect ranges in 2-year AAPL data, verify 3-5 significant ranges found
10. Performance: detect ranges in 1000 bars in <200ms

## Tasks / Subtasks

- [ ] **Task 1: Create TradingRangeDetector class structure** (AC: 1)
  - [ ] Create file: `backend/src/pattern_engine/trading_range_detector.py`
  - [ ] Import all dependencies from Stories 3.1-3.7:
    - `from backend.src.pattern_engine.pivot_detector import detect_pivots`
    - `from backend.src.pattern_engine.range_clusterer import cluster_pivots, form_trading_range`
    - `from backend.src.pattern_engine.range_quality import calculate_range_quality`
    - `from backend.src.pattern_engine.level_calculator import calculate_creek_level, calculate_ice_level, calculate_jump_level`
    - `from backend.src.pattern_engine.zone_mapper import map_supply_demand_zones`
  - [ ] Define class: `class TradingRangeDetector:`
  - [ ] Add comprehensive docstring explaining purpose and Wyckoff integration
  - [ ] Add class-level configuration attributes:
    - `lookback: int = 5` - pivot detection sensitivity
    - `pivot_tolerance_pct: Decimal = Decimal("0.02")` - clustering tolerance (2%)
    - `min_quality_threshold: int = 70` - minimum quality score
    - `cache_enabled: bool = True` - enable caching
  - [ ] Initialize structlog logger

- [ ] **Task 2: Implement primary detect_ranges method signature** (AC: 1, 3)
  - [ ] Create method: `def detect_ranges(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]:`
  - [ ] Add type hints for all parameters and return value
  - [ ] Add comprehensive docstring:
    - Purpose: orchestrate full range detection pipeline
    - Parameters: bars (500-1000 bars typical), volume_analysis (from Epic 2)
    - Returns: List[TradingRange] with all levels and zones populated
    - Performance: 1000 bars in <200ms
    - Algorithm: pivots → clustering → quality → levels → zones
  - [ ] Validate inputs:
    - bars not empty
    - volume_analysis length matches bars
    - bars are sequential (timestamps increasing)
    - minimum 20 bars required (insufficient for analysis below this)
  - [ ] Log detection start: symbol, timeframe, bar count, date range

- [ ] **Task 3: Implement Step 1 - Pivot Detection** (AC: 1, 10)
  - [ ] Call `pivots = detect_pivots(bars, lookback=self.lookback)`
  - [ ] Validate pivots returned (minimum 4 pivots needed: 2 highs, 2 lows)
  - [ ] If insufficient pivots: log warning and return empty list
  - [ ] Log pivot detection: total pivots, pivot highs, pivot lows
  - [ ] Performance check: ensure pivot detection completes in <50ms for 1000 bars

- [ ] **Task 4: Implement Step 2 - Pivot Clustering and Range Formation** (AC: 1, 3, 10)
  - [ ] Separate pivots: `pivot_highs = get_pivot_highs(pivots)`, `pivot_lows = get_pivot_lows(pivots)`
  - [ ] Cluster resistance candidates: `resistance_clusters = cluster_pivots(pivot_highs, tolerance_pct=self.pivot_tolerance_pct)`
  - [ ] Cluster support candidates: `support_clusters = cluster_pivots(pivot_lows, tolerance_pct=self.pivot_tolerance_pct)`
  - [ ] Form trading ranges by pairing support/resistance clusters:
    - For each support cluster, find compatible resistance cluster
    - Validate: resistance > support, minimum 3% range width, minimum 10 bars duration
    - Create `TradingRange` object using `form_trading_range(support_cluster, resistance_cluster, bars)`
  - [ ] Log clustering: resistance clusters found, support clusters found, candidate ranges formed
  - [ ] Performance check: ensure clustering completes in <30ms

- [ ] **Task 5: Implement Step 3 - Range Quality Scoring** (AC: 1, 7, 10)
  - [ ] For each candidate range, call `quality_score = calculate_range_quality(range, bars, volume_analysis)`
  - [ ] Filter ranges: keep only ranges with quality_score >= self.min_quality_threshold (70)
  - [ ] Log quality filtering:
    - Candidate ranges: count
    - Quality ranges (>=70): count
    - Rejected ranges (<70): count with reasons
  - [ ] Update range.quality_score field
  - [ ] Performance check: ensure quality scoring completes in <20ms

- [ ] **Task 6: Implement Step 4 - Level Calculation** (AC: 1, 2, 10)
  - [ ] For each quality range, calculate levels IN PARALLEL:
    - Creek level: `range.creek = calculate_creek_level(range, bars, volume_analysis)`
    - Ice level: `range.ice = calculate_ice_level(range, bars, volume_analysis)`
    - Jump level: `range.jump = calculate_jump_level(range)` (depends on creek/ice)
  - [ ] Validate levels:
    - creek.strength >= 60 (FR9)
    - ice.strength >= 60 (FR9)
    - creek.price < ice.price (support below resistance)
    - jump.price > ice.price (target above resistance)
  - [ ] Calculate range.midpoint: `(creek.price + ice.price) / 2`
  - [ ] Log level calculation: creek price, ice price, jump price, midpoint
  - [ ] Performance check: ensure level calculation completes in <30ms

- [ ] **Task 7: Implement Step 5 - Supply and Demand Zone Mapping** (AC: 1, 2, 10)
  - [ ] For each quality range with valid levels, call:
    - `zones = map_supply_demand_zones(range, bars, volume_analysis)`
  - [ ] Update range with zones:
    - `range.supply_zones = [z for z in zones if z.zone_type == ZoneType.SUPPLY]`
    - `range.demand_zones = [z for z in zones if z.zone_type == ZoneType.DEMAND]`
  - [ ] Log zone mapping: total zones, supply zones, demand zones, fresh zones
  - [ ] Performance check: ensure zone mapping completes in <20ms

- [ ] **Task 8: Implement overlapping range handling** (AC: 4)
  - [ ] Define overlap detection: `def _ranges_overlap(range1: TradingRange, range2: TradingRange) -> bool:`
    - Check if bar indices overlap: range1.end_index >= range2.start_index
    - Check if price levels overlap: (range1.creek.price <= range2.ice.price) AND (range1.ice.price >= range2.creek.price)
  - [ ] Implement resolution strategy:
    - **Newer ranges take precedence**: keep range with later end_index
    - Archive older range: set range.status = RangeStatus.ARCHIVED
    - Log overlap resolution: archived range ID, kept range ID, reason
  - [ ] Process ranges chronologically: sort by end_index before overlap detection
  - [ ] Return only ACTIVE ranges (not ARCHIVED)

- [ ] **Task 9: Implement range lifecycle management** (AC: 5)
  - [ ] Define RangeStatus enum in `backend/src/models/trading_range.py`:
    - FORMING: range detected but not confirmed (< 15 bars)
    - ACTIVE: range confirmed and valid (15-100 bars, quality >= 70)
    - BREAKOUT: price closed above Ice or below Creek (invalidated)
    - COMPLETED: range ended naturally (old data)
    - ARCHIVED: replaced by newer overlapping range
  - [ ] Add status field to TradingRange model: `status: RangeStatus = RangeStatus.FORMING`
  - [ ] Implement status transitions:
    - FORMING → ACTIVE: when duration >= 15 bars AND quality_score >= 70
    - ACTIVE → BREAKOUT: detect in future bars (not this story, Epic 5 responsibility)
    - ACTIVE → COMPLETED: when analyzing historical data, range ended
  - [ ] Set initial status based on duration and quality
  - [ ] Log status for each range detected

- [ ] **Task 10: Implement caching mechanism** (AC: 6)
  - [ ] Add cache dictionary: `self._range_cache: Dict[str, List[TradingRange]] = {}`
  - [ ] Create cache key: `def _create_cache_key(bars: List[OHLCVBar]) -> str:`
    - Key format: `"{symbol}:{timeframe}:{start_timestamp}:{end_timestamp}:{bar_count}"`
    - Example: "AAPL:1d:2024-01-01T00:00:00Z:2024-12-31T23:59:59Z:252"
  - [ ] Check cache before processing:
    - If cache_key exists and self.cache_enabled: return cached ranges
    - Log cache hit: "Range detection cache hit for {cache_key}"
  - [ ] Store results in cache after detection:
    - `self._range_cache[cache_key] = detected_ranges`
    - Log cache store: "Cached {count} ranges for {cache_key}"
  - [ ] Implement cache invalidation:
    - Method: `def clear_cache(self) -> None:` - clear all cached ranges
    - Method: `def invalidate_symbol(self, symbol: str) -> None:` - clear symbol-specific cache
  - [ ] Add cache statistics: hit count, miss count, total size

- [ ] **Task 11: Implement comprehensive logging** (AC: 7)
  - [ ] Log detection start: symbol, timeframe, bar count, start date, end date
  - [ ] Log each pipeline step completion:
    - Pivot detection: total pivots, highs, lows, duration
    - Clustering: resistance clusters, support clusters, candidate ranges
    - Quality scoring: quality ranges, rejected ranges
    - Level calculation: creek/ice/jump prices, strengths
    - Zone mapping: total zones, supply/demand breakdown
  - [ ] Log final summary when ranges detected:
    - Total ranges detected
    - Ranges by status (FORMING, ACTIVE, COMPLETED)
    - Average quality score
    - Date range coverage
  - [ ] Log performance metrics: total execution time, time per pipeline step
  - [ ] Use structured logging with correlation IDs for traceability
  - [ ] Follow architecture logging standards from [architecture/17-monitoring-and-observability.md]

- [ ] **Task 12: Add helper methods for range access** (AC: 2)
  - [ ] Create method: `def get_active_ranges(ranges: List[TradingRange]) -> List[TradingRange]:`
    - Filter by status == RangeStatus.ACTIVE
  - [ ] Create method: `def get_ranges_by_symbol(ranges: List[TradingRange], symbol: str) -> List[TradingRange]:`
    - Filter by range.symbol == symbol
  - [ ] Create method: `def get_most_recent_range(ranges: List[TradingRange]) -> TradingRange | None:`
    - Return range with latest end_index, or None if empty
  - [ ] Create method: `def get_range_at_timestamp(ranges: List[TradingRange], timestamp: datetime) -> TradingRange | None:`
    - Find range where timestamp falls within start/end timestamps
  - [ ] Add docstrings to all helper methods

- [ ] **Task 13: Write unit test with synthetic data** (AC: 8)
  - [ ] Create test file: `backend/tests/unit/pattern_engine/test_trading_range_detector.py`
  - [ ] Generate synthetic test scenario:
    - 100 bars with clear trading range (bars 30-70)
    - Pivot highs clustered near $180 (resistance)
    - Pivot lows clustered near $172 (support)
    - Range width: $8 (4.6% - adequate cause)
    - Duration: 40 bars (high quality, cause_factor=3.0x)
  - [ ] Generate corresponding VolumeAnalysis using Epic 2 VolumeAnalyzer
  - [ ] Call detector: `ranges = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Assert: 1 range detected
  - [ ] Assert range properties:
    - quality_score >= 70
    - creek.price ≈ $172
    - ice.price ≈ $180
    - jump.price ≈ $180 + (3.0 * $8) = $204
    - midpoint ≈ $176
    - status == RangeStatus.ACTIVE
    - supply_zones and demand_zones populated
  - [ ] Assert performance: execution time < 50ms (100 bars)

- [ ] **Task 14: Write unit test for overlapping range handling** (AC: 4)
  - [ ] Generate synthetic data with 2 overlapping ranges:
    - Range 1: bars 20-50, creek=$170, ice=$180
    - Range 2: bars 40-80, creek=$175, ice=$185 (newer, overlaps range 1)
  - [ ] Call detector: `ranges = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Assert: Only Range 2 is ACTIVE (Range 1 should be ARCHIVED)
  - [ ] Assert: archived range logged with reason "overlapping range resolved"

- [ ] **Task 15: Write unit test for lifecycle transitions** (AC: 5)
  - [ ] Test FORMING → ACTIVE:
    - Generate 10-bar range (< 15 bars): expect status=FORMING
    - Generate 20-bar range (>= 15 bars, quality 75): expect status=ACTIVE
  - [ ] Test quality rejection:
    - Generate range with quality_score=65 (<70): expect range filtered out
  - [ ] Verify status field in returned TradingRange objects

- [ ] **Task 16: Write unit test for caching** (AC: 6)
  - [ ] First call: `ranges1 = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Verify cache miss logged
  - [ ] Second call with same bars: `ranges2 = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Verify cache hit logged
  - [ ] Assert: ranges1 == ranges2 (same results)
  - [ ] Assert: second call is faster (no recomputation)
  - [ ] Test cache invalidation:
    - Call `detector.clear_cache()`
    - Third call: verify cache miss logged again

- [ ] **Task 17: Write integration test with realistic AAPL data** (AC: 9)
  - [ ] Create test file: `backend/tests/integration/pattern_engine/test_range_detector_integration.py`
  - [ ] Load 2-year AAPL daily data (504 bars, ~2 trading years)
  - [ ] Generate VolumeAnalysis using Epic 2 VolumeAnalyzer
  - [ ] Call detector: `ranges = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Assert: 3-5 significant ranges detected (realistic for 2-year period)
  - [ ] Verify range distribution:
    - Ranges spread throughout 2-year period (not clustered)
    - Average duration: 20-40 bars (1-2 months daily)
    - Average quality score >= 75
  - [ ] Verify all ranges have:
    - Valid creek, ice, jump levels
    - At least 1 supply zone or demand zone
    - Midpoint between creek and ice
  - [ ] Visual validation: log ranges for manual chart inspection
  - [ ] Log range details: start/end dates, creek/ice/jump prices, quality scores

- [ ] **Task 18: Write performance test** (AC: 10)
  - [ ] Create test file: `backend/tests/integration/pattern_engine/test_range_detector_performance.py`
  - [ ] Generate 1000 synthetic bars with 2-3 embedded ranges using factory-boy
  - [ ] Generate corresponding VolumeAnalysis
  - [ ] Measure execution time using `time.perf_counter()`
  - [ ] Call detector: `ranges = detector.detect_ranges(bars, volume_analysis)`
  - [ ] Assert: execution time < 200ms (AC 10 target)
  - [ ] Log performance breakdown:
    - Total time: Xms
    - Pivot detection: Yms
    - Clustering: Zms
    - Quality scoring: Ams
    - Level calculation: Bms
    - Zone mapping: Cms
  - [ ] Test with different data sizes: 252 bars, 500 bars, 1000 bars
  - [ ] Profile if performance target not met, identify bottlenecks

- [ ] **Task 19: Add comprehensive docstrings and usage examples**
  - [ ] Add module-level docstring to `trading_range_detector.py`:
    - Explain TradingRangeDetector purpose and role in Wyckoff analysis
    - Explain integration of Stories 3.1-3.7
    - Epic 3 deliverable: complete range detection system
  - [ ] Add class-level docstring to TradingRangeDetector:
    - Configuration options (lookback, tolerance, quality threshold)
    - Caching strategy
    - Performance characteristics
  - [ ] Add method docstring to detect_ranges:
    - Full pipeline description
    - Parameter details
    - Return value structure
    - Performance notes
    - Examples:
      ```python
      # Example: Detect trading ranges in AAPL data
      from backend.src.pattern_engine.trading_range_detector import TradingRangeDetector
      from backend.src.pattern_engine.volume_analyzer import VolumeAnalyzer
      from backend.src.repositories.ohlcv_repository import OHLCVRepository

      # Load data
      repo = OHLCVRepository()
      bars = repo.get_bars("AAPL", "1d", limit=252)

      # Analyze volume
      volume_analyzer = VolumeAnalyzer()
      volume_analysis = volume_analyzer.analyze_bars(bars)

      # Detect ranges
      detector = TradingRangeDetector(lookback=5, min_quality_threshold=70)
      ranges = detector.detect_ranges(bars, volume_analysis)

      # Access most recent range
      current_range = detector.get_most_recent_range(ranges)
      if current_range:
          print(f"Creek: {current_range.creek.price}")
          print(f"Ice: {current_range.ice.price}")
          print(f"Jump: {current_range.jump.price}")
          print(f"Quality: {current_range.quality_score}")
          print(f"Supply zones: {len(current_range.supply_zones)}")
          print(f"Demand zones: {len(current_range.demand_zones)}")
      ```

- [ ] **Task 20: Update TradingRange model for Epic 3.8** (AC: 2)
  - [ ] Update file: `backend/src/models/trading_range.py`
  - [ ] Ensure TradingRange has ALL required fields from AC 2:
    - `creek: CreekLevel` - support level (Story 3.4)
    - `ice: IceLevel` - resistance level (Story 3.5)
    - `jump: JumpLevel` - price target (Story 3.6)
    - `midpoint: Decimal` - (creek.price + ice.price) / 2
    - `quality_score: int` - 0-100 score (Story 3.3)
    - `duration: int` - number of bars in range
    - `supply_zones: List[Zone]` - supply zones (Story 3.7)
    - `demand_zones: List[Zone]` - demand zones (Story 3.7)
    - `status: RangeStatus` - lifecycle status (Story 3.8)
    - `start_index: int` - first bar index in range
    - `end_index: int` - last bar index in range
    - `start_timestamp: datetime` - first bar timestamp
    - `end_timestamp: datetime` - last bar timestamp
    - `symbol: str` - ticker symbol
    - `timeframe: str` - bar interval
  - [ ] Add computed properties:
    - `@property def range_width() -> Decimal:` return ice.price - creek.price
    - `@property def all_zones() -> List[Zone]:` return supply_zones + demand_zones
    - `@property def fresh_zones() -> List[Zone]:` return zones with strength=FRESH
    - `@property def is_active() -> bool:` return status == RangeStatus.ACTIVE
  - [ ] Configure JSON serialization for all Decimal and datetime fields

- [ ] **Task 21: Create visual validation script** (AC: 9)
  - [ ] Create script: `backend/scripts/visualize_complete_ranges.py`
  - [ ] Load 2-year AAPL data and detect ranges
  - [ ] Plot using matplotlib:
    - Candlestick chart or line chart of close prices
    - Horizontal lines for Creek (green), Ice (red), Jump (blue dashed)
    - Shaded rectangles for trading ranges (duration span)
    - Supply zones (red shaded areas)
    - Demand zones (green shaded areas)
    - Annotate with quality score, duration, range width
  - [ ] Save chart to file: `output/complete_ranges_AAPL.png`
  - [ ] Visual inspection checklist:
    - Ranges align with visible consolidation zones
    - Creek/Ice levels align with support/resistance
    - Jump targets are realistic (2-3x range width above Ice)
    - Supply/demand zones cluster near Ice/Creek
    - 3-5 ranges detected (not too many, not too few)
  - [ ] Test with multiple symbols: AAPL, SPY, QQQ, MSFT

- [ ] **Task 22: Document integration points for Epic 4-6**
  - [ ] Create integration guide: How Epic 4-6 pattern detectors will use TradingRangeDetector
  - [ ] Document required workflow:
    1. Load bars and volume analysis
    2. Call `detect_ranges()` to get trading ranges
    3. Filter for ACTIVE ranges
    4. Access creek, ice, jump levels for pattern validation
    5. Use demand zones for Spring entry optimization (Epic 4)
    6. Use supply zones for UTAD detection (Epic 5)
  - [ ] Add code example for Epic 4 integration:
    ```python
    # Epic 4: Spring Pattern Detection Integration
    ranges = detector.detect_ranges(bars, volume_analysis)
    active_ranges = [r for r in ranges if r.is_active]

    for range in active_ranges:
        # Spring pattern looks for:
        # 1. Price dips below Creek (range.creek.price)
        # 2. High volume on the dip
        # 3. Price closes back above Creek
        # 4. FRESH demand zone near Creek for entry

        fresh_demand_zones_near_creek = [
            z for z in range.demand_zones
            if z.strength == ZoneStrength.FRESH
            and z.proximity_to_level == "NEAR_CREEK"
        ]

        # If spring conditions met + fresh demand zone exists → high probability entry
    ```
  - [ ] Document that Epic 3.8 MUST be complete before Epic 4-6 can start

- [ ] **Task 23: Add error handling and edge cases**
  - [ ] Handle empty bars: return empty list, log warning
  - [ ] Handle insufficient pivots (< 4): return empty list, log warning
  - [ ] Handle no quality ranges: return empty list, log info
  - [ ] Handle level calculation failures (strength < 60): skip range, log warning
  - [ ] Handle zone mapping failures: continue with empty zones, log warning
  - [ ] Add try-except blocks around each pipeline step
  - [ ] Ensure partial failures don't crash entire detection
  - [ ] Log all errors with context (symbol, timeframe, bar range)

- [ ] **Task 24: Prepare for Epic 4-6 handoff**
  - [ ] Verify TradingRangeDetector is importable from `backend.src.pattern_engine.trading_range_detector`
  - [ ] Verify all models are importable and JSON-serializable
  - [ ] Create Epic 3 completion checklist:
    - [ ] All 8 stories (3.1-3.8) complete
    - [ ] All unit tests passing (>80% coverage)
    - [ ] All integration tests passing with AAPL data
    - [ ] Performance targets met (1000 bars < 200ms)
    - [ ] Visual validation successful (ranges align with charts)
    - [ ] Documentation complete (docstrings, examples)
  - [ ] Document known limitations:
    - Real-time range updates not implemented (will be Epic 7-8 concern)
    - Range breakout detection not implemented (Epic 5 responsibility)
    - Multiple timeframe analysis not supported yet

## Dev Notes

### Previous Story Context

**Stories 3.1-3.7 Completion:**
[Source: Epic 3 Stories]

**Story 3.1 - Pivot Detection:**
- Function: `detect_pivots(bars, lookback=5) -> List[Pivot]`
- Pivot model: bar, price, type (HIGH|LOW), strength, timestamp, index
- Performance: 1000 bars in <50ms
- Integration: Pivots are foundation for all range detection

**Story 3.2 - Clustering and Formation:**
- Functions: `cluster_pivots(pivots, tolerance_pct=0.02) -> List[PriceCluster]`
- Function: `form_trading_range(support_cluster, resistance_cluster, bars) -> TradingRange`
- Clustering within 2% price tolerance
- Minimum range requirements: 3% width, 10 bars duration
- Integration: Clustered pivots form trading range boundaries

**Story 3.3 - Quality Scoring:**
- Function: `calculate_range_quality(range, bars, volume_analysis) -> int`
- Score 0-100: duration (30 pts), touch count (30 pts), tightness (20 pts), volume (20 pts)
- Quality threshold: >= 70 required for valid range (FR1)
- Integration: Only quality ranges (>=70) proceed to level calculation

**Story 3.4 - Creek Level:**
- Function: `calculate_creek_level(range, bars, volume_analysis) -> CreekLevel`
- Volume-weighted average of pivot lows (support)
- Strength scoring: touch count, volume behavior, wicks, duration
- Minimum strength: 60 (FR9)
- Integration: Creek is support foundation for Spring patterns (Epic 4)

**Story 3.5 - Ice Level:**
- Function: `calculate_ice_level(range, bars, volume_analysis) -> IceLevel`
- Volume-weighted average of pivot highs (resistance)
- Same strength criteria as Creek
- Minimum strength: 60 (FR9)
- Integration: Ice is resistance ceiling for SOS breakout detection (Epic 5)

**Story 3.6 - Jump Level:**
- Function: `calculate_jump_level(range) -> JumpLevel`
- Wyckoff cause-effect method: jump = ice + (cause_factor × range_width)
- Cause factors: 40+ bars=3.0x, 25-39=2.5x, 15-24=2.0x
- Integration: Jump provides profit target for trade signals (Epic 5)

**Story 3.7 - Supply/Demand Zones:**
- Function: `map_supply_demand_zones(range, bars, volume_analysis) -> List[Zone]`
- Demand zones: high volume (>1.3x) + narrow spread (<0.8x) + close in upper 50%
- Supply zones: high volume + narrow spread + close in lower 50%
- Zone strength: FRESH (0 touches), TESTED (1-2), EXHAUSTED (3+)
- Proximity to Creek/Ice increases significance
- Integration: Fresh demand zones near Creek = optimal Spring entries (Epic 4)

**Key Learnings from Epic 3:**
- NumPy vectorization critical for performance (10-100x faster)
- Pydantic models auto-serialize correctly (Decimal → string)
- Structured logging with correlation IDs essential for debugging
- Visual validation catches logic errors unit tests miss
- factory-boy excellent for realistic test data generation
- Testing progression: Unit → Integration → Performance → Visual

**Epic 3.8 Integration Responsibility:**
- Story 3.8 (this story) orchestrates ALL previous stories into unified detector
- This is the DELIVERABLE for Epic 3
- Epic 4-6 pattern detectors depend on this integration
- Performance target cumulative: 1000 bars in <200ms (all 7 steps)

### Tech Stack & Dependencies

**Languages & Frameworks:**
[Source: [architecture/3-tech-stack.md](../../../docs/architecture/3-tech-stack.md#31-technology-stack-table)]
- Python 3.11+ (backend language)
- NumPy 1.26+ (array operations)
- pandas 2.2+ (optional, for rolling operations)
- Pydantic 2.5+ (TradingRange model, RangeStatus enum)
- pytest 8.0+ (testing framework)
- factory-boy (test data generation)
- structlog (logging)
- matplotlib (visual validation script)

**Module Locations:**
[Source: [architecture/10-unified-project-structure.md](../../../docs/architecture/10-unified-project-structure.md)]
- New Module: `backend/src/pattern_engine/trading_range_detector.py` (create new)
- Update Model: `backend/src/models/trading_range.py` (add status, ensure all fields)
- Unit Tests: `backend/tests/unit/pattern_engine/test_trading_range_detector.py` (create new)
- Integration Tests: `backend/tests/integration/pattern_engine/test_range_detector_integration.py` (create new)
- Performance Tests: `backend/tests/integration/pattern_engine/test_range_detector_performance.py` (create new)
- Visual Script: `backend/scripts/visualize_complete_ranges.py` (create new)

**Dependencies on Existing Code (Epic 3 Stories):**
- `backend/src/pattern_engine/pivot_detector.py`: detect_pivots (Story 3.1)
- `backend/src/pattern_engine/range_clusterer.py`: cluster_pivots, form_trading_range (Story 3.2)
- `backend/src/pattern_engine/range_quality.py`: calculate_range_quality (Story 3.3)
- `backend/src/pattern_engine/level_calculator.py`: calculate_creek_level, calculate_ice_level, calculate_jump_level (Stories 3.4-3.6)
- `backend/src/pattern_engine/zone_mapper.py`: map_supply_demand_zones (Story 3.7)
- `backend/src/models/trading_range.py`: TradingRange (Story 3.2)
- `backend/src/models/pivot.py`: Pivot, PivotType (Story 3.1)
- `backend/src/models/creek_level.py`: CreekLevel (Story 3.4)
- `backend/src/models/ice_level.py`: IceLevel (Story 3.5)
- `backend/src/models/jump_level.py`: JumpLevel (Story 3.6)
- `backend/src/models/zone.py`: Zone, ZoneType, ZoneStrength (Story 3.7)
- `backend/src/pattern_engine/volume_analyzer.py`: VolumeAnalyzer, VolumeAnalysis (Epic 2)
- `backend/src/models/ohlcv.py`: OHLCVBar (Epic 1)

### Data Models

**RangeStatus Enum (NEW - THIS STORY):**
[Source: Epic 3.8 AC 5 and Wyckoff methodology]

```python
from enum import Enum

class RangeStatus(str, Enum):
    """
    Lifecycle status of a trading range in Wyckoff analysis.

    FORMING: Range detected but not yet confirmed (< 15 bars duration)
    ACTIVE: Range confirmed and valid for pattern detection (15-100 bars, quality >= 70)
    BREAKOUT: Price closed above Ice or below Creek (range invalidated)
    COMPLETED: Range ended naturally in historical analysis (old data)
    ARCHIVED: Range replaced by newer overlapping range
    """
    FORMING = "FORMING"
    ACTIVE = "ACTIVE"
    BREAKOUT = "BREAKOUT"
    COMPLETED = "COMPLETED"
    ARCHIVED = "ARCHIVED"
```

**TradingRange Model (UPDATED - THIS STORY):**
[Source: Epic 3.8 AC 2 and Stories 3.1-3.7]

```python
from decimal import Decimal
from datetime import datetime
from typing import List
from uuid import UUID
from pydantic import BaseModel, Field, validator
from backend.src.models.creek_level import CreekLevel
from backend.src.models.ice_level import IceLevel
from backend.src.models.jump_level import JumpLevel
from backend.src.models.zone import Zone, ZoneType, ZoneStrength

class TradingRange(BaseModel):
    """
    Complete trading range with all levels and zones.

    Represents accumulation or distribution zone in Wyckoff analysis.
    Contains Creek (support), Ice (resistance), Jump (target) levels
    plus supply and demand zones for entry optimization.

    Attributes:
        id: Unique range identifier
        symbol: Ticker symbol (e.g., "AAPL")
        timeframe: Bar interval (e.g., "1d")
        creek: Support level (Story 3.4)
        ice: Resistance level (Story 3.5)
        jump: Price target level (Story 3.6)
        midpoint: (creek.price + ice.price) / 2
        quality_score: 0-100 quality score (Story 3.3)
        duration: Number of bars in range
        supply_zones: Supply zones within range (Story 3.7)
        demand_zones: Demand zones within range (Story 3.7)
        status: Lifecycle status (FORMING, ACTIVE, etc.)
        start_index: First bar index in range
        end_index: Last bar index in range
        start_timestamp: First bar timestamp
        end_timestamp: Last bar timestamp
    """
    id: UUID = Field(default_factory=uuid4)
    symbol: str = Field(..., max_length=20)
    timeframe: str = Field(..., max_length=5)

    # Levels (Stories 3.4-3.6)
    creek: CreekLevel = Field(..., description="Support level")
    ice: IceLevel = Field(..., description="Resistance level")
    jump: JumpLevel = Field(..., description="Price target")
    midpoint: Decimal = Field(..., decimal_places=8, max_digits=18, description="(creek + ice) / 2")

    # Quality and duration (Story 3.3)
    quality_score: int = Field(..., ge=0, le=100, description="Quality score 0-100")
    duration: int = Field(..., ge=10, description="Number of bars in range")

    # Zones (Story 3.7)
    supply_zones: List[Zone] = Field(default_factory=list, description="Supply zones (distribution)")
    demand_zones: List[Zone] = Field(default_factory=list, description="Demand zones (accumulation)")

    # Lifecycle (Story 3.8)
    status: RangeStatus = Field(default=RangeStatus.FORMING, description="Range lifecycle status")

    # Range boundaries
    start_index: int = Field(..., ge=0, description="First bar index")
    end_index: int = Field(..., ge=0, description="Last bar index")
    start_timestamp: datetime = Field(..., description="First bar timestamp")
    end_timestamp: datetime = Field(..., description="Last bar timestamp")

    @validator('midpoint')
    def validate_midpoint(cls, v, values):
        """Ensure midpoint is between creek and ice"""
        if 'creek' in values and 'ice' in values:
            creek_price = values['creek'].price
            ice_price = values['ice'].price
            expected_midpoint = (creek_price + ice_price) / Decimal("2.0")
            if abs(v - expected_midpoint) > Decimal("0.01"):
                raise ValueError(f"Midpoint {v} does not match (creek + ice) / 2 = {expected_midpoint}")
        return v

    @validator('end_index')
    def validate_indices(cls, v, values):
        """Ensure end_index > start_index"""
        if 'start_index' in values and v <= values['start_index']:
            raise ValueError(f"end_index {v} must be > start_index {values['start_index']}")
        return v

    @property
    def range_width(self) -> Decimal:
        """Range width in price points (ice - creek)"""
        return self.ice.price - self.creek.price

    @property
    def all_zones(self) -> List[Zone]:
        """All zones (supply + demand) sorted by significance"""
        zones = self.supply_zones + self.demand_zones
        return sorted(zones, key=lambda z: z.significance_score, reverse=True)

    @property
    def fresh_zones(self) -> List[Zone]:
        """Only FRESH zones (untested, highest quality)"""
        return [z for z in self.all_zones if z.strength == ZoneStrength.FRESH]

    @property
    def is_active(self) -> bool:
        """Whether range is currently active for pattern detection"""
        return self.status == RangeStatus.ACTIVE

    class Config:
        use_enum_values = True
        json_encoders = {
            Decimal: str,
            datetime: lambda v: v.isoformat()
        }
```

### Algorithm Details

**TradingRangeDetector Pipeline:**
[Source: Epic 3.8 AC and Stories 3.1-3.7 integration]

**Purpose:** Orchestrate all Epic 3 components into single unified detector for pattern detection use (Epics 4-6).

**Pipeline Steps:**

1. **Pivot Detection (Story 3.1):** ~50ms for 1000 bars
   - Input: bars, lookback=5
   - Output: List[Pivot] with swing highs and lows
   - Validation: minimum 4 pivots (2 highs, 2 lows)

2. **Clustering & Formation (Story 3.2):** ~30ms
   - Input: pivots, tolerance_pct=0.02
   - Process: Group pivots within 2% price tolerance
   - Output: List[TradingRange] candidate ranges
   - Validation: resistance > support, 3% width, 10+ bars

3. **Quality Scoring (Story 3.3):** ~20ms
   - Input: candidate ranges, bars, volume_analysis
   - Process: Score 0-100 based on duration, touches, tightness, volume
   - Output: Filtered ranges with quality_score >= 70
   - Validation: Only quality ranges proceed

4. **Level Calculation (Stories 3.4-3.6):** ~30ms
   - Input: quality ranges, bars, volume_analysis
   - Process: Calculate Creek, Ice, Jump levels (can parallelize)
   - Output: Ranges with creek, ice, jump, midpoint populated
   - Validation: creek < ice < jump, strengths >= 60

5. **Zone Mapping (Story 3.7):** ~20ms
   - Input: ranges with levels, bars, volume_analysis
   - Process: Detect supply/demand zones, calculate proximity
   - Output: Ranges with supply_zones, demand_zones populated
   - Validation: zones near Creek/Ice more significant

6. **Overlap Resolution (Story 3.8):** ~10ms
   - Input: all detected ranges
   - Process: Detect overlapping ranges, archive older ones
   - Output: Non-overlapping ACTIVE ranges
   - Validation: newer ranges take precedence

7. **Status Assignment (Story 3.8):** ~10ms
   - Input: final ranges
   - Process: Assign FORMING, ACTIVE, COMPLETED status
   - Output: Ranges with lifecycle status
   - Validation: ACTIVE requires 15+ bars and quality >= 70

**Total Performance Budget: <200ms for 1000 bars** (AC 10)

**Pseudocode:**

```python
def detect_ranges(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]:
    # Step 1: Pivot Detection (~50ms)
    pivots = detect_pivots(bars, lookback=self.lookback)
    if len(pivots) < 4:
        return []

    # Step 2: Clustering & Formation (~30ms)
    pivot_highs = get_pivot_highs(pivots)
    pivot_lows = get_pivot_lows(pivots)
    resistance_clusters = cluster_pivots(pivot_highs, tolerance_pct=self.pivot_tolerance_pct)
    support_clusters = cluster_pivots(pivot_lows, tolerance_pct=self.pivot_tolerance_pct)

    candidate_ranges = []
    for support in support_clusters:
        for resistance in resistance_clusters:
            if is_valid_range_pairing(support, resistance):
                range = form_trading_range(support, resistance, bars)
                candidate_ranges.append(range)

    # Step 3: Quality Scoring (~20ms)
    quality_ranges = []
    for range in candidate_ranges:
        range.quality_score = calculate_range_quality(range, bars, volume_analysis)
        if range.quality_score >= self.min_quality_threshold:
            quality_ranges.append(range)

    # Step 4: Level Calculation (~30ms)
    for range in quality_ranges:
        range.creek = calculate_creek_level(range, bars, volume_analysis)
        range.ice = calculate_ice_level(range, bars, volume_analysis)
        range.jump = calculate_jump_level(range)
        range.midpoint = (range.creek.price + range.ice.price) / Decimal("2.0")

        # Validate levels
        if range.creek.strength < 60 or range.ice.strength < 60:
            continue  # Skip low-strength levels

    # Step 5: Zone Mapping (~20ms)
    for range in quality_ranges:
        zones = map_supply_demand_zones(range, bars, volume_analysis)
        range.supply_zones = [z for z in zones if z.zone_type == ZoneType.SUPPLY]
        range.demand_zones = [z for z in zones if z.zone_type == ZoneType.DEMAND]

    # Step 6: Overlap Resolution (~10ms)
    non_overlapping_ranges = resolve_overlapping_ranges(quality_ranges)

    # Step 7: Status Assignment (~10ms)
    for range in non_overlapping_ranges:
        if range.duration >= 15 and range.quality_score >= 70:
            range.status = RangeStatus.ACTIVE
        else:
            range.status = RangeStatus.FORMING

    return non_overlapping_ranges
```

### Wyckoff Context

**Role of TradingRangeDetector in Wyckoff Analysis:**
[Source: Wyckoff methodology and BMAD framework]

**Wyckoff Trading Range Definition:**
> "An accumulation or distribution zone where smart money accumulates shares (demand) or distributes shares (supply) within defined support (Creek) and resistance (Ice) boundaries. The duration and quality of accumulation determines the effect (price movement magnitude measured by Jump target)."

**Epic 3 Deliverable:**
TradingRangeDetector provides the complete structural foundation for all Wyckoff pattern detection:

**For Epic 4 (Accumulation Patterns):**
- Spring pattern: tests Creek (support), bounces from demand zone
- Test pattern: validates Creek strength before SOS
- Last Point of Support (LPS): final test before markup

**For Epic 5 (Distribution Patterns):**
- Sign of Strength (SOS): breakout above Ice (resistance)
- UTAD pattern: tests Ice from above, supply zone rejection
- Backup to Ice: validates breakout before continuation

**For Epic 6 (Markup Patterns):**
- Jump target: profit-taking level based on cause-effect
- Trailing stop: adjusts based on range width

**Why This Integration Story is Critical:**
- Epic 4-6 need ONE interface, not 7 separate function calls
- Caching prevents redundant computation (same bars analyzed multiple times)
- Lifecycle management prevents using stale/broken ranges
- Overlap resolution ensures only valid ranges used for patterns
- **Without Story 3.8, Epic 4-6 cannot start** - this is the integration contract

### Coding Standards

**Naming Conventions:**
[Source: [architecture/15-coding-standards.md](../../../docs/architecture/15-coding-standards.md#152-naming-conventions)]
- Python Classes: PascalCase (e.g., `TradingRangeDetector`, `RangeStatus`)
- Python Functions: snake_case (e.g., `detect_ranges`, `resolve_overlapping_ranges`)
- Python Variables: snake_case (e.g., `quality_ranges`, `pivot_highs`)
- Constants: UPPER_SNAKE_CASE (e.g., `MIN_QUALITY_THRESHOLD`, `DEFAULT_LOOKBACK`)

**Type Safety:**
[Source: [architecture/15-coding-standards.md](../../../docs/architecture/15-coding-standards.md#151-critical-fullstack-rules)]
- ✅ Use type hints: `def detect_ranges(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]:`
- ✅ Use Pydantic models for data structures (TradingRange, RangeStatus)
- ✅ Use Decimal for all price calculations (midpoint, range_width)
- ✅ Use Enum for RangeStatus (type safety)
- ✅ Validate inputs (bars not empty, volume_analysis matches)

**Decimal Precision:**
[Source: [architecture/15-coding-standards.md](../../../docs/architecture/15-coding-standards.md#151-critical-fullstack-rules)]
- ✅ Use Decimal for midpoint: `(creek.price + ice.price) / Decimal("2.0")`
- ✅ Use Decimal for range_width: `ice.price - creek.price`
- ✅ Preserve Decimal through entire pipeline (no float conversion)
- ✅ TradingRange model uses Decimal for all price fields

### Error Handling & Logging

**Input Validation:**
[Source: Epic 3.8 AC and best practices]

```python
def detect_ranges(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]:
    # Validate inputs
    if not bars:
        logger.warning("empty_bars_list", message="Cannot detect ranges on empty bar list")
        return []

    if len(bars) < 20:
        logger.warning("insufficient_bars",
                      bars_count=len(bars),
                      required=20,
                      message="Insufficient bars for range detection")
        return []

    if len(volume_analysis) != len(bars):
        logger.error("bars_volume_mismatch",
                    bars_count=len(bars),
                    volume_count=len(volume_analysis),
                    message="Bars and volume_analysis length mismatch")
        raise ValueError("Bars and volume_analysis must have same length")

    # Validate sequential timestamps
    for i in range(1, len(bars)):
        if bars[i].timestamp <= bars[i-1].timestamp:
            logger.error("non_sequential_bars",
                        index=i,
                        message="Bars must be in chronological order")
            raise ValueError("Bars must have sequential timestamps")
```

**Logging Strategy:**
[Source: [architecture/17-monitoring-and-observability.md](../../../docs/architecture/17-monitoring-and-observability.md)]

```python
import structlog

logger = structlog.get_logger(__name__)

def detect_ranges(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[TradingRange]:
    symbol = bars[0].symbol
    timeframe = bars[0].timeframe
    start_time = time.perf_counter()

    logger.info("range_detection_start",
               symbol=symbol,
               timeframe=timeframe,
               bar_count=len(bars),
               date_range=f"{bars[0].timestamp} to {bars[-1].timestamp}")

    # Step 1: Pivots
    pivot_start = time.perf_counter()
    pivots = detect_pivots(bars, lookback=self.lookback)
    pivot_duration = (time.perf_counter() - pivot_start) * 1000
    logger.info("pivot_detection_complete",
               total_pivots=len(pivots),
               duration_ms=f"{pivot_duration:.2f}")

    # ... (continue for each step)

    # Final summary
    total_duration = (time.perf_counter() - start_time) * 1000
    logger.info("range_detection_complete",
               symbol=symbol,
               total_ranges=len(final_ranges),
               active_ranges=len([r for r in final_ranges if r.is_active]),
               avg_quality=sum(r.quality_score for r in final_ranges) / len(final_ranges) if final_ranges else 0,
               total_duration_ms=f"{total_duration:.2f}")

    return final_ranges
```

### Performance Requirements

**Performance Targets:**
[Source: Epic 3.8 AC 10 and Epic 3 overall]
- **1000 bars**: < 200ms (PRIMARY TARGET - AC 10)
- **500 bars**: < 100ms
- **252 bars** (1 year daily): < 50ms
- **Throughput**: > 5,000 bars/second

**Performance Budget Breakdown:**
- Pivot Detection: 50ms (Story 3.1 target)
- Clustering & Formation: 30ms (estimated)
- Quality Scoring: 20ms (estimated)
- Level Calculation: 30ms (3 levels calculated)
- Zone Mapping: 20ms (estimated)
- Overlap Resolution: 10ms (estimated)
- Status Assignment: 10ms (estimated)
- **Cache overhead**: 20ms (amortized over cache hits)
- **Total**: 190ms (10ms buffer for 200ms target)

**Performance Testing Strategy:**
[Source: [architecture/12-testing-strategy.md](../../../docs/architecture/12-testing-strategy.md)]
- Use `time.perf_counter()` for precise timing
- Test with 252, 500, 1000 bar datasets
- Measure each pipeline step individually
- Profile if targets not met (identify bottlenecks)
- Test cache performance (hit vs miss times)
- Compare with/without caching enabled

**Optimization Checklist:**
- ✅ Reuse pivot detection results (cache)
- ✅ Parallelize level calculation (Creek, Ice, Jump independent)
- ✅ Pre-filter low-quality ranges early (avoid level calculation)
- ✅ Minimize object creation (reuse where possible)
- ✅ Use NumPy for overlap detection (vectorized comparison)
- ⚠️ Profile zone mapping if slow (most complex step)

### Integration Notes

**Epic 4-6 Dependencies:**
[Source: Epic 4-6 PRD preview]

Epic 4-6 pattern detectors will use TradingRangeDetector as follows:

```python
# Epic 4: Spring Pattern Detector
from backend.src.pattern_engine.trading_range_detector import TradingRangeDetector

class SpringDetector:
    def __init__(self):
        self.range_detector = TradingRangeDetector(
            lookback=5,
            min_quality_threshold=70
        )

    def detect_spring(self, bars: List[OHLCVBar], volume_analysis: List[VolumeAnalysis]) -> List[SpringPattern]:
        # Step 1: Get trading ranges
        ranges = self.range_detector.detect_ranges(bars, volume_analysis)
        active_ranges = [r for r in ranges if r.is_active]

        # Step 2: For each active range, look for Spring
        springs = []
        for range in active_ranges:
            # Spring conditions:
            # 1. Price dips below Creek (range.creek.price)
            # 2. High volume on dip (volume_ratio > 1.5)
            # 3. Close back above Creek (rejection)
            # 4. FRESH demand zone near Creek for entry

            for bar in self._get_recent_bars(bars, range):
                if self._is_spring_bar(bar, range, volume_analysis):
                    # Find optimal entry in fresh demand zone
                    entry_zones = [
                        z for z in range.demand_zones
                        if z.strength == ZoneStrength.FRESH
                        and z.proximity_to_level == "NEAR_CREEK"
                    ]

                    if entry_zones:
                        spring = self._create_spring_pattern(bar, range, entry_zones[0])
                        springs.append(spring)

        return springs
```

**Required TradingRange Fields for Pattern Detection:**
- ✅ creek.price: Support level for Spring entry validation
- ✅ ice.price: Resistance level for SOS breakout validation
- ✅ jump.price: Profit target for trade signals
- ✅ demand_zones: Entry optimization (Spring, LPS)
- ✅ supply_zones: Resistance confirmation (UTAD, distribution)
- ✅ quality_score: Filter low-quality patterns
- ✅ status: Only ACTIVE ranges used for pattern detection

**Epic 3 Completion Criteria:**
- ✅ All 8 stories (3.1-3.8) complete and tested
- ✅ TradingRangeDetector tested with realistic AAPL data
- ✅ Performance target met (1000 bars < 200ms)
- ✅ Visual validation successful (ranges align with charts)
- ✅ Documentation complete (docstrings, integration examples)
- ✅ **Epic 4 can begin** (dependency satisfied)

## Testing

### Test File Locations
[Source: [architecture/10-unified-project-structure.md](../../../docs/architecture/10-unified-project-structure.md)]
- Unit Tests: `backend/tests/unit/pattern_engine/test_trading_range_detector.py` (create new)
- Integration Tests: `backend/tests/integration/pattern_engine/test_range_detector_integration.py` (create new)
- Performance Tests: `backend/tests/integration/pattern_engine/test_range_detector_performance.py` (create new)

### Testing Framework
[Source: [architecture/3-tech-stack.md](../../../docs/architecture/3-tech-stack.md#31-technology-stack-table)]
- pytest 8.0+ for all Python testing
- factory-boy for generating test OHLCV bars and TradingRange objects
- pytest.mark.parametrize for testing different configurations (lookback, quality threshold)
- time.perf_counter() for performance measurement
- pytest-benchmark for detailed performance profiling

### Test Coverage Requirements
- Unit tests for detect_ranges with synthetic data (AC 8)
- Unit tests for overlapping range handling (AC 4)
- Unit tests for lifecycle transitions (AC 5)
- Unit tests for caching (AC 6)
- Integration test with 2-year AAPL data (AC 9)
- Performance test: 1000 bars in <200ms (AC 10)
- Visual validation with multiple symbols

### Testing Standards
[Source: [architecture/12-testing-strategy.md](../../../docs/architecture/12-testing-strategy.md)]
- Unit tests: test integration logic with synthetic data
- Integration tests: test with realistic AAPL/SPY data
- Performance tests: measure execution time, verify targets met
- Coverage: aim for >80% code coverage
- Visual validation: manual inspection of charts with detected ranges
- Test both cached and non-cached paths

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-28 | 1.0 | Initial story creation with comprehensive technical context from Epic 3 stories and architecture docs | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
_This section will be populated by the development agent during implementation_

### Debug Log References
_This section will be populated by the development agent during implementation_

### Completion Notes List
_This section will be populated by the development agent during implementation_

### File List
_This section will be populated by the development agent during implementation_

## QA Results

### Review Date: 2025-10-29

### Reviewed By: Quinn (Test Architect)

### Pull Request Reviewed
- **PR #18**: https://github.com/jthadison/bmad4_wyck_vol/pull/18
- **Files Changed**: 3 (+1,418 additions, -0 deletions)
- **Test Results**: 15/17 unit tests passing (88%)
- **CI/CD Status**: ❌ ALL CHECKS FAILING (Lint, Type Check, Tests)

---

### Code Quality Assessment

**Overall Architecture Score: 85/100** ✅

**Strengths**:
1. **Exceptional orchestration design**: Successfully integrates all Epic 3 components (Stories 3.1-3.7) into unified interface
2. **Clean separation of concerns**: 7-step pipeline (pivots → clustering → quality → levels → zones → overlap → status) is well-architected
3. **Excellent documentation**: Comprehensive docstrings with examples, clear parameter descriptions, usage patterns documented
4. **Proper lifecycle management**: `RangeStatus` enum provides clear state machine for FORMING → ACTIVE → BREAKOUT → COMPLETED transitions
5. **Strong caching strategy**: Dictionary-based cache with symbol-specific invalidation, hit/miss tracking
6. **Good error handling**: Input validation, try-except blocks, extensive logging
7. **Helper functions**: Clean API with `get_active_ranges()`, `get_most_recent_range()`, etc.
8. **Performance tracking**: `time.perf_counter()` at each pipeline step with detailed breakdowns

**Implementation Quality**: Code is well-structured, readable, and follows good software engineering practices. The integration of 7 Epic 3 components is done correctly with proper error handling and logging at each step.

---

### Critical Blockers Found 🚨

#### 1. **CI/CD Failures** (SEVERITY: CRITICAL) ❌
**Status**: ALL 5 CHECKS FAILING
- Lint Backend: 100+ Python style violations
- Type Check Backend: Type annotation issues
- Test Backend: Test failures
- Lint Frontend: (cascade failure)
- Test Frontend: (cascade failure)

**Root Causes**:
- Using deprecated `typing.List`, `typing.Optional` instead of Python 3.11+ `list`, `X | None` syntax
- Import ordering violations (I001)
- Using `timezone.utc` instead of `datetime.UTC` (UP017)
- Type annotation modernization needed (UP006, UP007, UP035, UP037)

**Files Affected**:
- `backend/src/models/trading_range.py` (lines 12-113)
- `backend/src/pattern_engine/trading_range_detector.py`
- Cascade across entire backend codebase

**Fix Required**: Run `ruff check --fix .` && `ruff format .` then update type hints manually.

**Estimated Effort**: 2-3 hours

---

#### 2. **Missing Integration Test (AC9)** (SEVERITY: CRITICAL) ❌
**Status**: EXPLICITLY MARKED AS PENDING IN PR

AC9 requires: *"Integration test: detect ranges in 2-year AAPL data, verify 3-5 significant ranges found"*

**Impact**:
- **Blocks Epic 3 completion** - This story is the Epic 3 deliverable
- **Blocks Epic 4-6** - Pattern detectors depend on validated TradingRangeDetector
- **No real-world validation** - Only synthetic data tested

**Missing File**: `backend/tests/integration/pattern_engine/test_range_detector_integration.py`

**Requirements**:
- Load 2 years (504 bars) of AAPL daily data
- Generate VolumeAnalysis using Epic 2 VolumeAnalyzer
- Detect ranges and assert 3-5 significant ranges found
- Verify all ranges have valid creek, ice, jump levels
- Verify supply/demand zones populated
- Test with multiple symbols (AAPL, SPY, QQQ)

**Fix Required**: Implement complete integration test file per story Task 17.

**Estimated Effort**: 3-4 hours

---

#### 3. **Unit Test Failures** (SEVERITY: HIGH) ⚠️
**Status**: 2/17 TESTS FAILING (88% pass rate)

PR explicitly notes: *"⚠️ 2 tests need refinement (overlapping ranges, cache miss count)"*

**Failing Tests**:
1. `test_overlapping_range_handling`: Overlap detection assertions need refinement
2. `test_caching_mechanism`: Cache miss count assertion incorrect (expects 2, likely getting 1 or 3)

**Fix Required**: Debug and refine test assertions to match actual behavior.

**Estimated Effort**: 1-2 hours

---

#### 4. **Python 3.11+ Style Violations** (SEVERITY: HIGH) ⚠️
**Status**: 100+ LINTING VIOLATIONS

**Examples from `trading_range.py`**:
```python
# Line 12: VIOLATION
from typing import Optional, List, TYPE_CHECKING

# Should be:
from typing import TYPE_CHECKING
# (list, Optional handled by X | None syntax)

# Lines 103-113: VIOLATIONS
supply_zones: List["Zone"]  # UP006, UP037
creek: Optional[CreekLevel]  # UP007

# Should be:
supply_zones: list[Zone]    # Remove quotes, use builtin list
creek: CreekLevel | None    # Use union syntax

# Line 115: VIOLATION
datetime.now(timezone.utc)  # UP017

# Should be:
datetime.now(datetime.UTC)  # Use datetime.UTC alias
```

**Fix Required**: Update all type hints and imports to Python 3.11+ standards.

**Estimated Effort**: 2 hours

---

### Acceptance Criteria Validation

| AC | Requirement | Status | Notes |
|----|-------------|--------|-------|
| AC1 | `TradingRangeDetector` class with `detect_ranges()` | ✅ **PASS** | Correctly implemented |
| AC2 | TradingRange contains all required fields | ✅ **PASS** | creek, ice, jump, zones, midpoint all present |
| AC3 | Batch processing 500-bar sequences | ✅ **PASS** | Tests with 100 bars, scales to 500-1000 |
| AC4 | Overlapping range handling | ⚠️ **FAIL** | Logic implemented but test failing |
| AC5 | Range lifecycle (FORMING → ACTIVE) | ✅ **PASS** | Status transitions tested |
| AC6 | Caching mechanism | ✅ **PASS** | Cache implemented, but test has assertion issue |
| AC7 | Comprehensive logging | ✅ **PASS** | Excellent structlog usage throughout |
| AC8 | Unit test with synthetic data | ⚠️ **FAIL** | 15/17 passing (88%) |
| AC9 | Integration test with 2-year AAPL | ❌ **FAIL** | **MISSING - BLOCKS EPIC 3** |
| AC10 | Performance: 1000 bars < 200ms | ✅ **PASS** | 100-bar test passes scaled assertion |

**Coverage**: 6/10 fully met, 2/10 partial (failing tests), 2/10 fail (AC4, AC9)

**Gap Analysis**:
- **AC4**: Implementation correct, test needs refinement
- **AC9**: Completely missing, non-negotiable requirement
- **Visual validation (AC21)**: Script not mentioned in PR

---

### Refactoring Performed

**⚠️ NO REFACTORING PERFORMED** - Due to scope and nature of issues:

1. **Linting violations**: 100+ violations require systematic ruff fixes across entire backend
2. **Integration test**: 3-4 hour effort to implement properly with real data
3. **Test failures**: Require debugging to understand root cause
4. **CI/CD state**: All checks failing makes refactoring unsafe

**Rationale**: The blockers are too extensive for QA agent to fix during review. Developer must systematically address linting, implement integration test, and fix failing tests. QA refactoring would risk introducing breaking changes without CI/CD validation.

**Recommendation**: Developer should:
1. Run `ruff check --fix . && ruff format .` first
2. Manually update type hints to Python 3.11+ syntax
3. Implement AC9 integration test
4. Debug and fix 2 failing unit tests
5. Verify all CI/CD checks pass
6. Request re-review

---

### Standards Compliance Check

| Standard | Status | Evidence |
|----------|--------|----------|
| ✅ **Coding Standards** | ❌ **FAIL** | 100+ linting violations, deprecated type hints |
| ✅ **Project Structure** | ✅ **PASS** | Files in correct locations per architecture/10-unified-project-structure.md |
| ✅ **Testing Strategy** | ❌ **FAIL** | Integration test missing, 2 unit tests failing |
| ✅ **Documentation** | ✅ **PASS** | Excellent docstrings, examples, module-level docs |
| ✅ **Performance** | ✅ **PASS** | Meets AC10 target (100 bars < 50ms, scales to 1000 < 200ms) |
| ✅ **Error Handling** | ✅ **PASS** | Good validation and logging, minor concerns with generic exceptions |

---

### Requirements Traceability (Given-When-Then)

#### AC1: TradingRangeDetector class
**Given** bars and volume_analysis
**When** `detect_ranges()` called
**Then** returns List[TradingRange] with all levels populated
**Test**: `test_detect_ranges_with_synthetic_data` ✅

#### AC2: TradingRange fields
**Given** detected range
**When** accessing fields
**Then** creek, ice, jump, midpoint, quality_score, zones all present
**Test**: `test_detect_ranges_with_synthetic_data` (field assertions) ✅

#### AC3: Batch processing
**Given** 500-1000 bar sequence
**When** `detect_ranges()` called
**Then** all ranges detected in single pass
**Test**: `test_detect_ranges_with_synthetic_data` (100 bars) ✅

#### AC4: Overlapping ranges
**Given** 2 overlapping ranges
**When** newer range detected
**Then** older range archived, only newer active
**Test**: `test_overlapping_range_handling` ⚠️ FAILING

#### AC5: Lifecycle
**Given** range duration < 15 bars
**When** status assigned
**Then** status = FORMING
**Test**: `test_lifecycle_forming_to_active` ✅

**Given** range duration >= 15 bars AND quality >= 70
**When** status assigned
**Then** status = ACTIVE
**Test**: `test_lifecycle_forming_to_active` ✅

#### AC6: Caching
**Given** same bars called twice
**When** second call made
**Then** cache hit, results returned faster
**Test**: `test_caching_mechanism` ⚠️ FAILING (assertion issue)

#### AC7: Logging
**Given** range detection
**When** pipeline executes
**Then** info logs at each step with metrics
**Evidence**: Code review shows extensive structlog usage ✅

#### AC8: Unit tests
**Given** synthetic data
**When** tests run
**Then** all tests pass
**Test**: 15/17 passing ⚠️ 88% (target: 100%)

#### AC9: Integration test
**Given** 2-year AAPL data
**When** `detect_ranges()` called
**Then** 3-5 ranges detected with valid levels
**Test**: **MISSING** ❌ CRITICAL GAP

#### AC10: Performance
**Given** 1000 bars
**When** `detect_ranges()` called
**Then** completes in < 200ms
**Test**: `test_performance_target` (100 bars < 50ms, scaled) ✅

**Gap Summary**: AC4 (test failing), AC9 (completely missing)

---

### Security Review

**Status**: ✅ **PASS** - No security concerns

**Analysis**:
- ✅ No authentication/authorization handling (N/A for this story)
- ✅ No payment processing (N/A)
- ✅ Pydantic models prevent SQL injection
- ✅ No sensitive data exposure (market data is public)
- ✅ No file system operations (cache in-memory)
- ✅ Input validation present (bars not empty, length checks)
- ✅ No external API calls with secrets

**Conclusion**: This is a pure data processing module with no security surface area.

---

### Performance Considerations

**Status**: ⚠️ **CONCERNS** - Meets requirements but optimization opportunities exist

#### Measured Performance:
- ✅ 100 bars: Target <50ms → **Test passes**
- ✅ 1000 bars: Target <200ms → **Scaled test suggests compliance**

#### Performance Concerns:

**1. Overlap Resolution Algorithm (Lines 557-615)** - **O(n²) complexity**
```python
for candidate in sorted_ranges:
    overlaps_with_active = False
    for active in active_ranges:  # Nested loop
        if self._ranges_overlap(candidate, active):
            # ... logic ...
            active_ranges.remove(active)  # List mutation during iteration
```

**Risk Assessment**:
- **Current**: O(n²) where n = number of ranges
- **Typical n**: 3-5 ranges (per AC9), max ~10
- **Impact**: Low risk for n<10, but scales poorly
- **Recommendation**: Future optimization with interval tree (O(n log n))

**2. Missing 1000-Bar Test**
- AC10 requires 1000 bars < 200ms
- Only 100-bar test exists with scaled assertion
- Should add explicit 1000-bar performance test in integration suite

**3. Caching Strategy** ✅ **EXCELLENT**
- Cache hit avoids entire pipeline recomputation
- Symbol-specific invalidation prevents stale data
- Cache key includes timestamp range for precision

**Overall**: Meets AC10 target, but O(n²) algorithm is technical debt.

---

### Non-Functional Requirements (NFR) Validation

#### **Security**: ✅ **PASS**
- No security surface area for this module
- Pydantic validation prevents injection
- No sensitive data handling

#### **Performance**: ⚠️ **CONCERNS**
- Meets AC10 target (100 bars < 50ms)
- O(n²) overlap algorithm acceptable for n<10
- No actual 1000-bar test (only scaled assertion)
- Caching strategy excellent

#### **Reliability**: ⚠️ **CONCERNS**
- **Good**: Input validation, try-except blocks, extensive logging
- **Concern**: Broad `except Exception` blocks catch too generically
- **Concern**: Silent range rejection in level calculation (lines 403-408)
  ```python
  except Exception as e:
      logger.warning("level_calculation_failed", ...)
      # Range silently dropped, no mechanism to track WHY
  ```
- **Mitigation**: Logging captures context, but custom exceptions would be better

#### **Maintainability**: ✅ **PASS**
- **Excellent**: Documentation, clear code structure, helper functions
- **Minor**: `detect_ranges()` is 400 lines long (lines 131-530)
  - Could extract pipeline steps to separate methods
  - Would improve testability and readability
- **Minor**: Linting violations hurt consistency

---

### Technical Debt Identified

#### **Immediate Debt** (Must fix for merge):
1. ❌ **CI/CD Failures**: All checks failing, blocks merge
2. ❌ **Missing AC9 Integration Test**: Blocks Epic 3 completion and Epic 4-6
3. ⚠️ **2 Failing Unit Tests**: 88% pass rate, need refinement
4. ⚠️ **Linting Violations**: 100+ style issues

#### **Future Debt** (Can defer):
1. **O(n²) Overlap Algorithm**: Use interval tree for O(n log n)
2. **Long Method**: Extract `detect_ranges()` pipeline steps
3. **Generic Exception Handling**: Define custom domain exceptions
4. **Missing Visual Validation**: AC21 script not implemented

**Total Estimated Debt**: 10-15 hours (6-10 immediate, 4-5 future)

---

### Test Architecture Assessment

#### **Unit Tests**: 80/100 ⚠️
**Strengths**:
- ✅ Excellent synthetic data generation (`generate_trading_range_scenario`)
- ✅ Clear test documentation (40-bar range, $172-$180 levels)
- ✅ Helper functions for test data creation
- ✅ Good edge case coverage (empty bars, insufficient bars, length mismatch)
- ✅ Performance testing included

**Concerns**:
- ❌ 2 tests failing (overlapping ranges, cache miss count)
- ⚠️ No actual 1000-bar test (only scaled 100-bar test)

#### **Integration Tests**: 0/100 ❌
**Status**: **COMPLETELY MISSING**

AC9 explicitly requires:
- 2-year AAPL data (504 bars)
- Verify 3-5 significant ranges detected
- Validate all ranges have creek, ice, jump levels
- Verify supply/demand zones populated
- Test with multiple symbols (AAPL, SPY, QQQ)

**Impact**: **Blocks Epic 3 completion and Epic 4-6 start**

#### **Performance Tests**: 70/100 ⚠️
- ✅ 100-bar test with `time.perf_counter()`
- ⚠️ Only scaled assertion for 1000-bar target
- ❌ Should add explicit 1000-bar test

#### **Overall Test Score**: 50/100 ❌
Unit tests strong but integration tests missing is critical.

---

### Testability Evaluation

#### **Controllability**: ✅ **EXCELLENT** (95/100)
- Synthetic data generators provide full control
- Helper functions create deterministic scenarios
- Configuration via constructor parameters
- Dependency injection for all Epic 3 components

#### **Observability**: ✅ **EXCELLENT** (95/100)
- Comprehensive structlog output at every step
- Performance metrics tracked (pivot: 50ms, clustering: 30ms, etc.)
- Cache hit/miss tracking
- All intermediate results logged with correlation IDs
- Range IDs in all logs for traceability

#### **Debuggability**: ✅ **GOOD** (80/100)
- **Strengths**: Clear error messages with context, range IDs in logs, performance breakdown
- **Concerns**: Generic Exception catching could be more specific, silent range rejection

---

### Improvements Checklist

**Immediate (Must fix before merge)**:
- [ ] Fix all linting violations with `ruff check --fix . && ruff format .`
- [ ] Update type hints to Python 3.11+ syntax (List → list, Optional → X | None)
- [ ] Fix import ordering violations
- [ ] Implement AC9 integration test with 2-year AAPL data
- [ ] Fix `test_overlapping_range_handling` assertions
- [ ] Fix `test_caching_mechanism` cache miss count assertion
- [ ] Add explicit 1000-bar performance test
- [ ] Verify all CI/CD checks pass

**Future (Can defer)**:
- [ ] Optimize overlap resolution with interval tree (O(n log n))
- [ ] Extract `detect_ranges()` pipeline steps to separate methods
- [ ] Define custom exceptions (InsufficientPivotsError, LowQualityRangeError, etc.)
- [ ] Create visual validation script (AC21) with matplotlib
- [ ] Add more specific exception handling instead of generic Exception

---

### Files Modified During Review

**None** - Scope of issues requires developer to systematically address with CI/CD validation.

---

### Gate Status

**Gate**: **FAIL** → [docs/qa/gates/3.8-trading-range-detector-integration.yml](../../qa/gates/3.8-trading-range-detector-integration.yml)

**Quality Score**: **20/100**
- Calculation: 100 - (20 × 4 high-severity issues) = 20

**Risk Profile**: **HIGH (9/10)**
- **Component**: Epic 3 Completion - Risk: 9/10 (blocks Epic 4-6)
- **Component**: CI/CD Pipeline - Risk: 8/10 (all checks failing)
- **Component**: Pattern Detection - Risk: 9/10 (downstream dependency)

**Decision Rationale**:
Despite excellent architecture (85/100) and implementation quality, this story cannot pass due to critical blockers:
1. **All CI/CD checks failing** - Cannot merge
2. **AC9 integration test missing** - Blocks Epic 3 completion and Epic 4-6
3. **2 unit tests failing** - 88% pass rate vs 100% required
4. **100+ linting violations** - Style compliance failure

The code quality is strong and would be PASS if tests passed, but delivery is incomplete. The integration test is non-negotiable as it validates the entire Epic 3 pipeline with real market data.

**Estimated Effort to PASS**: 6-10 hours
- Fix linting: 2-3 hours
- Implement AC9: 3-4 hours
- Fix failing tests: 1-2 hours
- Add 1000-bar test: 1 hour

---

### Recommended Status

❌ **Changes Required** - See unchecked items in Improvements Checklist above

**Blocking Issues**:
1. All CI/CD checks must pass
2. AC9 integration test must be implemented (blocks Epic 3 completion)
3. 2 unit tests must pass (100% pass rate required)
4. Linting violations must be resolved

**Next Steps**:
1. Run `ruff check --fix . && ruff format .`
2. Manually update type hints to Python 3.11+ standards
3. Implement `test_range_detector_integration.py` with 2-year AAPL data
4. Debug and fix `test_overlapping_range_handling` and `test_caching_mechanism`
5. Add explicit 1000-bar performance test
6. Verify all CI/CD checks pass
7. Request re-review from Quinn

**Story Owner Decision Required**: Once all blockers resolved, update Status to "Done" and merge PR.

---

### Positive Highlights ⭐

Despite the blockers, the implementation quality is excellent:

1. **Outstanding orchestration design** - Correctly integrates all 7 Epic 3 components into unified interface
2. **Excellent documentation** - Comprehensive docstrings with examples, clear usage patterns
3. **Strong test data generation** - `generate_trading_range_scenario()` creates realistic synthetic data
4. **Proper Pydantic models** - TradingRange updated with all required fields, proper validation
5. **Comprehensive logging** - Structured logs with performance breakdown at each pipeline step
6. **Clean API design** - Helper functions provide intuitive interface for Epic 4-6 consumers
7. **Good error handling** - Input validation, try-except blocks, extensive logging
8. **Smart caching strategy** - Dictionary cache with symbol-specific invalidation, hit/miss tracking
9. **Proper lifecycle management** - RangeStatus enum provides clear state machine

**Architecture Assessment**: 85/100 - This is high-quality software engineering. The blockers are delivery/process issues (CI/CD, missing tests) rather than fundamental design problems.

---

### Final Summary

**Overall Assessment**: **Implementation EXCELLENT (85/100), Delivery INCOMPLETE (20/100)**

This is a well-architected, well-documented integration of Epic 3 components. The code quality demonstrates strong software engineering practices. However, critical delivery blockers prevent merge:

- ❌ All CI/CD checks failing
- ❌ AC9 integration test missing (blocks Epic 3 completion)
- ⚠️ 2 unit tests failing
- ⚠️ 100+ linting violations

**The core blocker is AC9** - Without integration testing on real market data (2-year AAPL), we cannot validate that the TradingRangeDetector works end-to-end. This blocks Epic 4-6 pattern detectors from starting.

**Recommendation**: Developer should systematically address blockers (estimated 6-10 hours), then request re-review. The code quality is strong enough that once blockers are resolved, this should quickly move to PASS.

**Quinn's Assessment**: This is the kind of code I want to see - well-documented, properly tested (unit), good architecture. The missing integration test is a procedural issue, not a code quality issue. Fix the blockers and this will be a solid Epic 3 completion.
