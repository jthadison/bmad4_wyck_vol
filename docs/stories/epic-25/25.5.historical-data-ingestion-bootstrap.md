# Story 25.5: Historical Data Ingestion Bootstrap

## Status
Done

## Story
**As a** developer,
**I want** a documented, reliable mechanism to load historical OHLCV data into the database for any symbol and timeframe,
**So that** the orchestrator has bars to analyze on a fresh deployment without requiring a pre-populated database.

## INVEST Checklist
| Criteria | Status | Notes |
|----------|--------|-------|
| Independent | ✅ | Existing data provider adapters exist; no cross-story dependencies |
| Negotiable | ✅ | Endpoint shape and CLI interface flexible |
| Valuable | ✅ | Fresh deployments produce zero signals without this; system is unusable |
| Estimable | ✅ | Clear scope: one endpoint, one startup check, one CLI script |
| Small | ✅ | 3 points — focused on wiring existing adapters, not new data logic |
| Testable | ✅ | bars_inserted count and idempotency are directly testable |

## Story Points
3

## Priority
P0 Critical

## Type
Feature

## Dependencies
None

## Background

`backend/src/orchestrator/orchestrator_facade.py` lines 796–812 query PostgreSQL for OHLCV bars. A fresh deployment has zero records. `_fetch_bars()` returns `[]` silently, analysis produces zero signals, and there is no documented or automated mechanism to populate the database.

The system already has data provider adapters (Polygon, Alpaca, Yahoo) that can fetch historical bars. However, no endpoint or script uses them to seed the database. Developers deploying the system for the first time have no path to getting data in.

This story creates three things:
1. A `POST /api/v1/data/ingest` REST endpoint that accepts symbol, timeframe, start_date, end_date and fetches + stores bars using the configured provider
2. A startup check in `main.py` that logs a warning listing any watchlist symbols that have zero bars in the database
3. A CLI script `scripts/ingest_historical.py` for batch seeding from the command line

## Acceptance Criteria

### AC1: Ingest Endpoint Accepts and Stores Bars
```gherkin
Given a POST request to /api/v1/data/ingest with body { symbol: "AAPL", timeframe: "1d", start_date: "2024-01-01", end_date: "2024-12-31" }
When the endpoint is called with a valid configured data provider
Then bars are fetched from the provider for the specified range
And each bar is stored in the ohlcv table in the database
And the endpoint returns HTTP 200
```

### AC2: Ingestion Response Includes Summary
```gherkin
Given a successful ingestion of 252 bars for AAPL
When the endpoint returns
Then the response body contains bars_fetched, bars_inserted, symbol, timeframe, date_range
And bars_inserted <= bars_fetched (duplicates excluded)
```

### AC3: Startup Warning When No Data Exists
```gherkin
Given a watchlist configuration containing symbols ["AAPL", "SPY", "QQQ"]
And the ohlcv table contains zero bars for "QQQ"
When the API server starts
Then a WARNING log entry is written listing "QQQ" as having no historical data
And the server still starts successfully (warning only, not a startup failure)
```

### AC4: CLI Script Works from Command Line
```gherkin
Given the command: python scripts/ingest_historical.py --symbol AAPL --timeframe 1d --days 500
When the script is executed with a valid configured provider
Then bars are fetched and inserted into the database
And the script prints the number of bars inserted to stdout
And exits with code 0
```

### AC5: Duplicate Bars Not Inserted
```gherkin
Given AAPL 1d bars for 2024-01-01 to 2024-06-30 already exist in the database
When the ingest endpoint is called again for the overlapping range 2024-03-01 to 2024-09-30
Then bars for 2024-01-01 to 2024-06-30 are not duplicated
And only the new bars (2024-07-01 to 2024-09-30) are inserted
And bars_inserted in the response reflects only the new rows
```

### AC6: Provider Error Surfaced Clearly
```gherkin
Given an invalid or expired Polygon API key in the environment
When the ingest endpoint is called
Then the response is HTTP 422 with an error body that includes the provider name and a message describing the authentication failure
And no synthetic or placeholder data is silently inserted
```

## Tasks / Subtasks

- [ ] **Task 1**: Read existing data infrastructure
  - [ ] Read `backend/src/market_data/service.py` — understand fetch interface
  - [ ] Read `backend/src/market_data/adapters/polygon_adapter.py` — confirm historical fetch method
  - [ ] Read `backend/src/repositories/ohlcv_repository.py` — confirm insert/upsert method
  - [ ] Read `backend/src/api/main.py` — understand route registration and startup hooks

- [ ] **Task 2**: Create ingest route
  - [ ] Create `backend/src/api/routes/data/ingest.py`
  - [ ] Define `IngestRequest` Pydantic model (symbol, timeframe, start_date, end_date)
  - [ ] Define `IngestResponse` Pydantic model (bars_fetched, bars_inserted, symbol, timeframe, date_range)
  - [ ] Implement POST handler: fetch from provider → upsert to DB → return summary

- [ ] **Task 3**: Register route in main.py
  - [ ] Import and register the ingest router in `main.py`
  - [ ] Confirm the route appears in `/docs` (Swagger)

- [ ] **Task 4**: Add startup warning for missing data
  - [ ] Read watchlist symbols from config at startup
  - [ ] Query ohlcv_repository for bar count per symbol
  - [ ] Log WARNING for each symbol with zero bars
  - [ ] Confirm server still starts (do not raise on warning)

- [ ] **Task 5**: Create CLI script
  - [ ] Create `scripts/ingest_historical.py`
  - [ ] Accept --symbol, --timeframe, --days arguments
  - [ ] Reuse the same service/repository layer as the endpoint
  - [ ] Print bars_inserted to stdout, exit 0 on success

- [ ] **Task 6**: Handle duplicate prevention
  - [ ] Confirm ohlcv_repository uses upsert or INSERT ... ON CONFLICT DO NOTHING
  - [ ] If not, add it

- [ ] **Task 7**: Write tests
  - [ ] Unit test: IngestRequest validation (required fields, date format)
  - [ ] Unit test: duplicate prevention — mock repo, assert insert count reflects only new bars
  - [ ] Unit test: provider error → 422 response
  - [ ] Integration test: mock provider → bars stored → bars_inserted > 0

- [ ] **Task 8**: Run quality gates
  - [ ] `ruff check` + `ruff format`
  - [ ] `mypy src/`
  - [ ] `pytest tests/ -x --cov`

## Dev Notes

### Key Files to Modify
- `backend/src/api/routes/data/ingest.py` — new file, ingest endpoint
- `backend/src/api/main.py` — register route + add startup warning check

### Key Files to Reference (read-only)
- `backend/src/market_data/service.py` — existing fetch interface
- `backend/src/market_data/adapters/polygon_adapter.py` — historical data fetch
- `backend/src/repositories/ohlcv_repository.py` — insert/upsert interface

### Approach
Read the existing market data service and repository before writing any new code. Reuse existing fetch and store primitives — do not reimplement data access. The endpoint should be a thin coordinator: validate input → call market_data service → call repository → return summary. Keep the CLI script as a thin wrapper around the same service layer, not a separate implementation.

## Testing

### Test File Location
`backend/tests/unit/api/routes/data/test_ingest.py`

### Testing Framework
pytest 8.0+ with pytest-asyncio

### Test Requirements
1. Unit test: valid request → bars_inserted > 0 in response
2. Unit test: duplicate call → bars_inserted = 0 (all already present)
3. Unit test: invalid API key → 422 with provider error message
4. Unit test: startup warning logic — mock repo returning 0 bars for one symbol → WARNING logged
5. Integration test: full endpoint call with mocked provider → DB insert confirmed

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|

## Review
- Philip (Phase Detector) — Verify minimum bar count (at least 50 bars) is warned about for reliable pattern detection
- Sam (Level Mapper) — Verify data quality (OHLCV completeness) is validated before insertion
