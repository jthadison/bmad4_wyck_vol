# Story 2.3: Close Position Analysis

## Status
Done
Ready for Development

## Story

**As a** volume analyzer,
**I want** to calculate close position (where in the bar's range the close occurred),
**so that** pattern detectors can determine buying vs. selling pressure.

## Acceptance Criteria

1. Function implemented: `calculate_close_position(bar: OHLCVBar) -> float`
2. Formula: close_position = (close - low) / (high - low)
3. Returns value 0.0 to 1.0 (0.0 = closed at low, 1.0 = closed at high)
4. Handle edge case: if high == low (zero spread), return 0.5 (neutral)
5. Close position stored in VolumeAnalysis object
6. Unit test: close at high returns 1.0, close at low returns 0.0, close at midpoint returns 0.5
7. Unit test: zero spread bar returns 0.5
8. Integration test: identify bars with close in upper 30% (close_position >= 0.7) for bullish absorption
9. Integration test: identify bars with close in lower 30% (close_position <= 0.3) for bearish distribution
10. Validation: close_position always in [0.0, 1.0] range

## Tasks / Subtasks

- [ ] **Task 1: Implement `calculate_close_position` function** (AC: 1, 2, 3, 4)
  - [ ] Add function to existing `backend/src/pattern_engine/volume_analyzer.py` module
  - [ ] Create function signature: `calculate_close_position(bar: OHLCVBar) -> float`
  - [ ] Extract values from bar: `close`, `high`, `low`
  - [ ] Calculate spread: `spread = high - low`
  - [ ] Handle edge case: if `spread == 0` (high == low), return 0.5 (neutral position)
  - [ ] Calculate close position: `close_position = (close - low) / spread`
  - [ ] Validate result is in [0.0, 1.0] range
  - [ ] Return close_position as float
  - [ ] Add docstring with formula explanation and examples

- [ ] **Task 2: Add input validation and error handling** (AC: 10)
  - [ ] Validate bar parameter is not None
  - [ ] Ensure close, high, low are valid Decimal values
  - [ ] Add assertion or validation: `low <= close <= high` (data integrity check)
  - [ ] Log warning if close is outside [low, high] range (data quality issue)
  - [ ] Ensure returned value is always in [0.0, 1.0] range
  - [ ] Add type hints for all parameters and return values

- [ ] **Task 3: Update VolumeAnalysis data model** (AC: 5)
  - [ ] Modify existing `VolumeAnalysis` model in `backend/src/models/volume_analysis.py`
  - [ ] Update `close_position` field from placeholder to active field with proper typing
  - [ ] Field definition: `close_position: Optional[Decimal] = Field(None, decimal_places=4, max_digits=5, ge=0.0, le=1.0)`
  - [ ] Add field validator to ensure close_position is in [0.0, 1.0] range
  - [ ] Verify JSON serialization for Decimal fields works correctly
  - [ ] Maintain backward compatibility with Story 2.1 (volume_ratio) and Story 2.2 (spread_ratio) fields

- [ ] **Task 4: Write unit tests for basic close position calculation** (AC: 6)
  - [ ] Create/update test file: `backend/tests/unit/pattern_engine/test_volume_analyzer.py`
  - [ ] Test close at high: bar with close = high, expect 1.0
  - [ ] Test close at low: bar with close = low, expect 0.0
  - [ ] Test close at midpoint: bar with close = (high + low) / 2, expect 0.5
  - [ ] Test close at 75% of range: expect 0.75
  - [ ] Test close at 25% of range: expect 0.25
  - [ ] Use pytest parametrization for multiple test scenarios
  - [ ] Verify precision: result should have 4 decimal places

- [ ] **Task 5: Write unit test for edge case (zero spread)** (AC: 7)
  - [ ] Create test case: bar with high == low (zero spread, doji bar)
  - [ ] Assert close_position returns 0.5 (neutral) per AC 4
  - [ ] Test various scenarios: close == high == low at different price levels
  - [ ] Verify no division by zero errors occur
  - [ ] Verify result is exactly 0.5 for all zero spread cases

- [ ] **Task 6: Write unit tests for data validation** (AC: 10)
  - [ ] Test invalid data: close > high (should log warning, handle gracefully)
  - [ ] Test invalid data: close < low (should log warning, handle gracefully)
  - [ ] Test edge values: close exactly at low (0.0), close exactly at high (1.0)
  - [ ] Test precision: very small spreads (e.g., 0.0001), verify calculation accuracy
  - [ ] Verify all return values are in [0.0, 1.0] range

- [ ] **Task 7: Write integration test for bullish absorption detection** (AC: 8)
  - [ ] Create/update test file: `backend/tests/integration/pattern_engine/test_volume_analysis_integration.py`
  - [ ] Generate 252 bars with various close positions
  - [ ] Create subset with bullish closes (close_position >= 0.7)
  - [ ] Calculate close positions for entire sequence
  - [ ] Assert bars with close in upper 30% are correctly identified
  - [ ] Cross-reference with volume_ratio and spread_ratio to identify bullish absorption:
    - High volume + narrow spread + close_position >= 0.7 = bullish absorption
  - [ ] Log statistics: count of bullish bars, average close position

- [ ] **Task 8: Write integration test for bearish distribution detection** (AC: 9)
  - [ ] Generate 252 bars with bearish close patterns (close_position <= 0.3)
  - [ ] Calculate close positions for entire sequence
  - [ ] Assert bars with close in lower 30% are correctly identified
  - [ ] Cross-reference with volume_ratio and spread_ratio to identify bearish distribution:
    - High volume + narrow spread + close_position <= 0.3 = bearish distribution
  - [ ] Log statistics: count of bearish bars, average close position
  - [ ] Compare bullish vs bearish bar distribution to verify data quality

- [ ] **Task 9: Write integration test for pressure analysis** (AC: 8, 9, 10)
  - [ ] Create realistic bar sequence with mixed pressure signals
  - [ ] Categorize bars by close position:
    - Strong buying pressure: close_position >= 0.7
    - Neutral/balanced: 0.3 < close_position < 0.7
    - Strong selling pressure: close_position <= 0.3
  - [ ] Calculate statistics over 252-bar period:
    - % of bars with buying pressure
    - % of bars with selling pressure
    - % of bars neutral
    - Average close position
  - [ ] Verify distribution is realistic (not all bars at extremes)
  - [ ] Test alignment with Wyckoff patterns (Springs should close high, UTAD should close low)

- [ ] **Task 10: Add logging and observability** (AC: all)
  - [ ] Import structlog for structured logging (consistent with Stories 2.1 and 2.2)
  - [ ] Log warning when close is outside [low, high] range (data quality issue)
  - [ ] Log debug info for edge cases (zero spread bars)
  - [ ] Add correlation ID support for tracing (future-proofing)
  - [ ] Follow logging standards from architecture/17-monitoring-and-observability.md
  - [ ] Log statistics during batch processing (future Story 2.5 integration)

- [ ] **Task 11: Performance optimization** (AC: all)
  - [ ] Ensure function is lightweight (simple arithmetic, no loops)
  - [ ] Function should execute in <1µs per bar (much faster than volume/spread ratio)
  - [ ] Prepare for vectorized batch processing in Story 2.5
  - [ ] Add inline comments explaining calculation efficiency
  - [ ] Consider numpy vectorization for batch mode (optional optimization)

- [ ] **Task 12: Integration preparation for VolumeAnalyzer class** (AC: 5)
  - [ ] Ensure calculate_close_position function signature is compatible with future VolumeAnalyzer.analyze() method
  - [ ] Verify function can be called in batch processing mode (Story 2.5 integration)
  - [ ] Add docstring with usage examples and parameter descriptions
  - [ ] Document Wyckoff interpretation of close position values:
    - 0.8-1.0: Strong buying pressure (bullish)
    - 0.6-0.8: Moderate buying pressure
    - 0.4-0.6: Neutral/balanced
    - 0.2-0.4: Moderate selling pressure
    - 0.0-0.2: Strong selling pressure (bearish)
  - [ ] Prepare for integration with effort_result classification (Story 2.4)

## Dev Notes

### Previous Story Insights

**Key Learnings from Story 2.1 (Volume Ratio) and Story 2.2 (Spread Ratio):**
- Established pattern: Functions in `backend/src/pattern_engine/volume_analyzer.py`
- VolumeAnalysis model created in Story 2.1 with placeholders, spread_ratio activated in Story 2.2
- NumPy vectorization pattern established for ratio calculations (Stories 2.1, 2.2)
- Edge case pattern: Return None for insufficient data (volume/spread ratio) or neutral value (this story: 0.5)
- Testing pattern: Unit → Integration → Performance tests
- Decimal precision: 4 decimal places for ratios (NUMERIC(10,4) in DB)
- Zero handling: Log warning, return appropriate value
- Module structure already exists, this story extends with close position calculation

**Differences from Stories 2.1 and 2.2:**
- **Simpler calculation**: No 20-bar window required, single bar calculation
- **No None values**: Always returns a valid value (0.0 to 1.0 or 0.5 for edge case)
- **Faster performance**: Simple arithmetic vs. rolling average
- **Direct interpretation**: 0.0 (bearish) to 1.0 (bullish), intuitive scale
- **Edge case handling**: Zero spread returns 0.5 (neutral), not None

**Technical Consistency Requirements:**
- Follow same module structure as Stories 2.1 and 2.2
- Maintain consistent error handling and logging patterns
- Use same VolumeAnalysis model (activate close_position field)
- Align testing structure (unit, integration, performance)
- Use structlog for logging consistency

### Tech Stack & Dependencies

**Languages & Frameworks:**
[Source: [architecture/3-tech-stack.md](../architecture/3-tech-stack.md#31-technology-stack-table)]
- Python 3.11+ (backend language)
- Pydantic 2.5+ (data validation and modeling)
- pytest 8.0+ (testing framework)
- pytest-mock + factory-boy (test data generation)
- NumPy 1.26+ (optional for batch vectorization in Story 2.5)

**Module Location:**
[Source: [architecture/10-unified-project-structure.md](../architecture/10-unified-project-structure.md)]
- Implementation: `backend/src/pattern_engine/volume_analyzer.py` (EXISTING module from Stories 2.1, 2.2)
- Models: `backend/src/models/volume_analysis.py` (EXISTING model, update close_position field)
- Unit Tests: `backend/tests/unit/pattern_engine/test_volume_analyzer.py` (EXISTING, add close position tests)
- Integration Tests: `backend/tests/integration/pattern_engine/test_volume_analysis_integration.py` (EXISTING, add pressure analysis tests)

### Data Models

**OHLCVBar Model:**
[Source: [architecture/4-data-models.md](../architecture/4-data-models.md#41-ohlcvbar-candlestick-data)]
```python
class OHLCVBar(BaseModel):
    id: UUID
    symbol: str = Field(..., max_length=20)
    timeframe: Literal["1m", "5m", "15m", "1h", "1d"]
    timestamp: datetime  # Always UTC
    open: Decimal = Field(..., decimal_places=8, max_digits=18)
    high: Decimal = Field(..., decimal_places=8, max_digits=18)
    low: Decimal = Field(..., decimal_places=8, max_digits=18)
    close: Decimal = Field(..., decimal_places=8, max_digits=18)
    volume: int = Field(..., ge=0)
    spread: Decimal = Field(..., decimal_places=8, max_digits=18)
    spread_ratio: Decimal = Field(..., decimal_places=4, max_digits=10)
    volume_ratio: Decimal = Field(..., decimal_places=4, max_digits=10)
    created_at: datetime
```

**VolumeAnalysis Model (UPDATE from Stories 2.1 and 2.2):**
[Source: Stories 2.1, 2.2 and Epic 2 requirements]
```python
class VolumeAnalysis(BaseModel):
    bar: OHLCVBar  # Reference to analyzed bar
    volume_ratio: Optional[Decimal] = Field(None, decimal_places=4, max_digits=10)  # Story 2.1
    spread_ratio: Optional[Decimal] = Field(None, decimal_places=4, max_digits=10)  # Story 2.2
    close_position: Optional[Decimal] = Field(None, decimal_places=4, max_digits=5, ge=0.0, le=1.0)  # THIS STORY
    effort_result: Optional[str] = None  # Story 2.4 - Placeholder
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
```

**IMPORTANT NOTE:** The VolumeAnalysis model was created in Story 2.1 with `close_position` as a placeholder. This story activates that field by implementing the calculation logic.

### Calculations & Algorithms

**Close Position Calculation:**
[Source: Epic 2.3 Requirements]
- Formula: `close_position = (close - low) / (high - low)`
- This represents where the bar closed within its range
- 0.0 = closed at the low (maximum selling pressure)
- 1.0 = closed at the high (maximum buying pressure)
- 0.5 = closed at midpoint (neutral/balanced pressure)
- Edge case: if `high == low` (zero spread), return 0.5 (neutral)

**Wyckoff Interpretation of Close Position:**
[Source: Epic 2 Overview and Wyckoff Theory]
- **Close Position >= 0.7**: Strong buying pressure
  - Bullish signal, especially when combined with high volume
  - Springs should close high (0.7-1.0) to be valid
  - Bullish absorption: high volume + narrow spread + high close
- **Close Position <= 0.3**: Strong selling pressure
  - Bearish signal, especially when combined with high volume
  - UTAD should close low (0.0-0.3) to be valid
  - Bearish distribution: high volume + narrow spread + low close
- **Close Position 0.4-0.6**: Neutral/balanced pressure
  - Indecision or equilibrium between buyers and sellers
  - May indicate consolidation or transition phase
- **Close in context with Volume and Spread:**
  - High volume + narrow spread + close at high (0.7+) = **Bullish Absorption** (accumulation)
  - High volume + narrow spread + close at low (0.0-0.3) = **Bearish Absorption** (distribution)
  - High volume + wide spread + close at high = **Climactic Buying** (potential reversal)
  - High volume + wide spread + close at low = **Selling Climax** (potential reversal)

**Calculation Efficiency:**
[Source: Performance requirements]
- Simple arithmetic operation: subtract, divide
- No loops, no window calculations
- Function should execute in <1µs per bar
- Much faster than volume_ratio and spread_ratio (no 20-bar averaging)
- Suitable for real-time processing and batch processing

### Database Schema

**OHLCV Bars Table:**
[Source: [architecture/9-database-schema.md](../architecture/9-database-schema.md)]
```sql
CREATE TABLE ohlcv_bars (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    symbol VARCHAR(20) NOT NULL,
    timeframe VARCHAR(5) NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    open NUMERIC(18,8) NOT NULL,
    high NUMERIC(18,8) NOT NULL,
    low NUMERIC(18,8) NOT NULL,
    close NUMERIC(18,8) NOT NULL,
    volume BIGINT NOT NULL CHECK (volume >= 0),
    spread NUMERIC(18,8) NOT NULL,
    spread_ratio NUMERIC(10,4) NOT NULL,
    volume_ratio NUMERIC(10,4) NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(symbol, timeframe, timestamp)
);
```

**Note:** Close position is not stored in the `ohlcv_bars` table because it can be efficiently calculated on-the-fly from `close`, `high`, and `low`. It will be stored in the VolumeAnalysis object for pattern detection use. Future optimization could add a `close_position` column if needed.

### Coding Standards

**Naming Conventions:**
[Source: [architecture/15-coding-standards.md](../architecture/15-coding-standards.md#152-naming-conventions)]
- Python Classes: PascalCase (e.g., `VolumeAnalyzer`, `VolumeAnalysis`)
- Python Functions: snake_case (e.g., `calculate_close_position`)
- Database Tables: snake_case (e.g., `ohlcv_bars`)

**Type Safety:**
[Source: [architecture/15-coding-standards.md](../architecture/15-coding-standards.md#151-critical-fullstack-rules)]
- ✅ Use Pydantic models for all data structures
- ✅ Use `Decimal` type for financial calculations (not `float`)
- ❌ Do not use `float` or `number` for close position
- ✅ Use field validators to enforce [0.0, 1.0] range constraint

**Decimal Precision:**
[Source: [architecture/15-coding-standards.md](../architecture/15-coding-standards.md) and Stories 2.1, 2.2]
- Close position: 4 decimal places (e.g., 0.7523)
- Database storage (if added): NUMERIC(5,4) (range: 0.0000 to 1.0000)
- Pydantic model: `Field(..., decimal_places=4, max_digits=5, ge=0.0, le=1.0)`

### Error Handling

**Edge Cases to Handle:**
[Source: Epic 2.3 AC and [architecture/16-error-handling-strategy.md](../architecture/16-error-handling-strategy.md)]
1. **Zero spread**: high == low (doji bar, no movement), return 0.5 per AC 4
2. **Data integrity**: close outside [low, high] range, log warning and clamp value
3. **Invalid input**: bar parameter is None, validate and raise appropriate error
4. **Validation**: Ensure result is always in [0.0, 1.0] range per AC 10
5. **Precision**: Handle very small spreads (e.g., 0.0001) without precision loss

**Logging Strategy:**
[Source: [architecture/17-monitoring-and-observability.md](../architecture/17-monitoring-and-observability.md)]
- Use `structlog` for structured JSON logging
- Log warnings when close is outside [low, high] range (data quality issue)
- Log debug info for zero spread bars (doji patterns)
- Include correlation IDs for distributed tracing (future-proofing)
- Follow same logging pattern as Stories 2.1 and 2.2

**Error Example:**
```python
if spread == 0:
    logger.debug(
        "zero_spread_bar",
        symbol=bar.symbol,
        timestamp=bar.timestamp,
        price=bar.close,
        message="Doji bar detected (high == low), returning neutral position 0.5"
    )
    return Decimal("0.5")

if not (bar.low <= bar.close <= bar.high):
    logger.warning(
        "invalid_close_position_data",
        symbol=bar.symbol,
        timestamp=bar.timestamp,
        close=bar.close,
        low=bar.low,
        high=bar.high,
        message="Close is outside [low, high] range, data quality issue"
    )
    # Clamp close to [low, high] range
    close = max(bar.low, min(bar.close, bar.high))
```

### Performance Requirements

**Performance Targets:**
[Source: Epic 2.3 requirements and Story 2.1/2.2 consistency]
- Process single bar in <1µs (microsecond)
- Process 10,000 bars in <10ms total (100x faster than volume/spread ratio)
- No performance testing required (calculation is trivial)
- Suitable for real-time tick-by-tick processing

**Optimization Techniques:**
- Simple arithmetic operations only (no loops, no external calls)
- No NumPy required for single bar calculation (overhead not justified)
- Optional: Vectorized batch mode for Story 2.5 using NumPy arrays
- Avoid type conversions inside function (keep as Decimal throughout)

### Integration Notes

**Future Integration Points:**
1. **Story 2.4**: Effort vs. result classification will use close_position with volume_ratio and spread_ratio
2. **Story 2.5**: VolumeAnalyzer class will call calculate_close_position in batch processing
3. **Pattern Detectors**: Springs, UTAD, SOS detectors will use close_position for validation:
   - Spring must close high (>= 0.7) to be valid
   - UTAD must close low (<= 0.3) to be valid
   - Tests should close high or neutral
4. **Signal Generation**: Close position used to confirm pattern strength and directionality

**Dependencies:**
- Story 2.1 (Volume Ratio) must be complete - VolumeAnalysis model and module exist
- Story 2.2 (Spread Ratio) must be complete - Module structure established
- This story is foundational for Story 2.4 (Effort vs. Result classification)
- Pattern detection epics (3-6) depend on complete VolumeAnalysis (Stories 2.1-2.4)

**Shared Module Context:**
- `volume_analyzer.py` module created in Story 2.1, extended in Story 2.2, this story adds close position
- VolumeAnalysis model created in Story 2.1, spread_ratio activated in Story 2.2, this story activates close_position
- Test files created in Story 2.1, extended in Story 2.2, this story adds close position tests
- Follow established patterns for consistency and maintainability

### Architectural Context

**Backtesting-First Design:**
[Source: Stories 2.1, 2.2 and architectural patterns]
- The `calculate_close_position` function must work on both live and historical bars
- Function is stateless and pure (no side effects)
- Identical code paths for live trading and backtesting
- No dependencies on external data sources

**Repository Pattern:**
[Source: Stories 2.1, 2.2 and architectural patterns]
- Future stories will create `VolumeAnalysisRepository` for data persistence
- This story focuses on calculation logic only, not database integration
- Keep business logic separate from data access layer
- Calculation functions should be pure (no side effects)

## Testing

### Test File Locations
[Source: [architecture/10-unified-project-structure.md](../architecture/10-unified-project-structure.md)]
- Unit tests: `backend/tests/unit/pattern_engine/test_volume_analyzer.py` (EXISTING from Stories 2.1, 2.2, add close position tests)
- Integration tests: `backend/tests/integration/pattern_engine/test_volume_analysis_integration.py` (EXISTING from Stories 2.1, 2.2, add pressure analysis tests)

### Testing Framework
[Source: [architecture/3-tech-stack.md](../architecture/3-tech-stack.md)]
- pytest 8.0+ for all Python testing
- pytest-mock for mocking dependencies
- factory-boy for generating test OHLCV bars
- pytest.mark.parametrize for multiple test scenarios

### Test Data Generation
[Source: [architecture/3-tech-stack.md](../architecture/3-tech-stack.md) and Stories 2.1, 2.2]
- Use factory-boy to create OHLCVBar test fixtures
- Create bars with various close positions:
  - Close at high (1.0)
  - Close at low (0.0)
  - Close at midpoint (0.5)
  - Close at 75% (0.75)
  - Close at 25% (0.25)
- Create edge cases: zero spread bars (doji)
- Label test data with expected close positions

### Testing Standards
[Source: [architecture/12-testing-strategy.md](../architecture/12-testing-strategy.md)]
- Follow testing pyramid: unit tests (fast) → integration tests
- Mock external dependencies in unit tests (none for this function)
- Use real data structures in integration tests
- Measure test coverage (aim for >80% for critical modules)
- Parametrize tests for multiple scenarios

### Test Scenarios

**Unit Test Scenarios:**
1. Close at high: high=100, low=90, close=100, expect 1.0
2. Close at low: high=100, low=90, close=90, expect 0.0
3. Close at midpoint: high=100, low=90, close=95, expect 0.5
4. Close at 75%: high=100, low=90, close=97.5, expect 0.75
5. Close at 25%: high=100, low=90, close=92.5, expect 0.25
6. Edge case: Zero spread (high=100, low=100, close=100), expect 0.5
7. Edge case: Close > high (invalid data), expect clamped value or warning
8. Edge case: Close < low (invalid data), expect clamped value or warning
9. Precision: Very small spread (0.0001), verify calculation accuracy
10. Validation: All results in [0.0, 1.0] range

**Integration Test Scenarios:**
1. **Bullish absorption detection** (AC 8):
   - 252 bars with various close positions
   - Identify bars with close_position >= 0.7
   - Cross-reference with high volume + narrow spread
   - Verify bullish absorption patterns detected
2. **Bearish distribution detection** (AC 9):
   - 252 bars with bearish patterns
   - Identify bars with close_position <= 0.3
   - Cross-reference with high volume + narrow spread
   - Verify bearish distribution patterns detected
3. **Pressure analysis**:
   - Categorize bars by pressure (buying, neutral, selling)
   - Calculate statistics over 252-bar period
   - Verify realistic distribution (not all extremes)
   - Test alignment with Wyckoff patterns
4. **Combined analysis**:
   - Use close_position with volume_ratio and spread_ratio
   - Identify climax patterns (volume + spread + close)
   - Identify absorption patterns
   - Verify pattern logic aligns with Wyckoff theory

**No Performance Testing Required:**
- Calculation is trivial (simple arithmetic)
- Performance will far exceed requirements (<1µs per bar)
- Integration tests provide adequate performance validation

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-18 | 1.0 | Initial story creation with comprehensive technical context | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
_This section will be populated by the development agent during implementation_

### Debug Log References
_This section will be populated by the development agent during implementation_

### Completion Notes List
_This section will be populated by the development agent during implementation_

### File List
_This section will be populated by the development agent during implementation_

## QA Results
_This section will be populated by the QA agent after story completion_
