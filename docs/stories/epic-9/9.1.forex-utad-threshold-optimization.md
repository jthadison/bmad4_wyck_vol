# Story 9.1: Forex UTAD Threshold Optimization & Backtesting

**Epic:** 9 - Validation Analytics & Optimization
**Status:** Backlog
**Story Points:** 5
**Priority:** P2 - High Value
**Dependencies:** Story 8.3.1 (Forex Volume Validation), Story 8.5 (Level Validation)

---

## User Story

**As a** Wyckoff trading system operator,
**I want** to optimize the forex UTAD volume threshold (250% vs 200%) using production data,
**so that** we maximize valid UTAD signal generation without compromising Wyckoff authenticity.

---

## Problem Statement

Story 8.3.1 implemented a **250% volume threshold** for forex UTAD patterns based on Wyckoff crew recommendations. However, Victoria (Volume Specialist) suggested this threshold might be **too conservative** and recommended monitoring rejection rates.

The system currently logs "near-miss" rejections (200-250% range) at INFO level for future analysis. After 2-3 months of production data, we need to:

1. **Analyze near-miss patterns** - Are we rejecting valid Wyckoff UTAD setups?
2. **Backtest alternative thresholds** - Would 200%, 220%, or 230% improve signal quality?
3. **Session-specific optimization** - Should OVERLAP session use different thresholds than ASIAN?
4. **Update configuration** - Implement data-driven threshold adjustments

---

## Background

### Current Implementation (Story 8.3.1)

**File:** `backend/src/signal_generator/validators/volume_validator.py:660-668`

```python
# Wyckoff crew P2: Log forex UTAD near-misses (200-250% range)
if context.asset_class == "FOREX" and Decimal("2.0") <= volume_ratio < threshold:
    logger.info(
        "forex_utad_near_miss",
        volume_ratio=float(volume_ratio),
        threshold=float(threshold),
        symbol=context.symbol,
        session=context.forex_session.value if context.forex_session else None,
        note="UTAD rejected but would pass at 200% threshold",
    )
```

**Current Thresholds:**
- **Stock UTAD:** 200% (1.2x → 2.0x per Story 0.2)
- **Forex UTAD:** 250% (2.5x)
- **Forex UTAD (Asian session):** 300% (3.0x - low liquidity adjustment)

### Wyckoff Principles

**UTAD (Upthrust After Distribution):**
- **Wyckoff Definition:** Supply climax at end of distribution phase
- **Volume Characteristic:** Elevated volume showing institutional distribution completing
- **Risk:** Too high threshold → miss valid UTAD setups where professionals exit quietly
- **Risk:** Too low threshold → false signals from retail panic (noise)

**Victoria's Guidance (Story 8.3.1 Review):**
> "UTAD threshold (250%): Potentially too strict. After monitoring rejection rates for 2-3 months, consider testing 200% vs 250% in backtests. This is NOT blocking - data will guide optimization."

---

## Acceptance Criteria

### Phase 1: Data Collection & Analysis (AC: 1-4)

1. **Log Analysis Script** - Query production logs for `forex_utad_near_miss` events
   - Time range: Last 90 days of production data
   - Group by: forex_session (ASIAN/LONDON/NY/OVERLAP), symbol, volume_ratio range
   - Output: CSV with near-miss statistics

2. **Session-Specific Patterns** - Analyze rejection rates by session
   - OVERLAP: Expected high liquidity → potentially lower rejections
   - LONDON: Expected high liquidity → moderate rejections
   - ASIAN: Expected low liquidity → higher rejections (stricter threshold correct)
   - NY: Expected high liquidity → moderate rejections

3. **Volume Distribution Analysis** - Calculate percentiles of rejected UTAD volumes
   - 25th percentile: Barely missed (e.g., 2.1x)
   - 50th percentile: Median near-miss (e.g., 2.3x)
   - 75th percentile: Close to passing (e.g., 2.45x)

4. **Symbol-Specific Patterns** - Identify if certain pairs show consistent near-misses
   - EUR/USD: Major pair, high liquidity
   - GBP/JPY: Volatile pair, may have different volume characteristics
   - USD/CHF: Low volume pair, may need different threshold

### Phase 2: Backtesting Framework (AC: 5-8)

5. **Historical UTAD Dataset** - Extract historical UTAD patterns from database
   - Last 12 months of UTAD patterns (both passed and near-missed)
   - Include: symbol, timestamp, volume_ratio, session, outcome (if signal generated)
   - Filter: Only patterns where we have post-pattern price data (4+ weeks)

6. **Outcome Classification** - Label historical UTADs as "valid" or "false"
   - **Valid UTAD:** Price declined ≥50% of range within 4 weeks (distribution confirmed)
   - **False UTAD:** Price rallied back above UTAD high (distribution failed)
   - **Neutral:** Price stayed within range (inconclusive)

7. **Threshold Sweep Test** - Backtest volume thresholds from 180% to 280% (20% increments)
   - For each threshold:
     - Calculate: How many patterns would pass?
     - Calculate: Precision (% of passed patterns that were "valid")
     - Calculate: Recall (% of "valid" patterns that would pass)
   - Find optimal threshold that maximizes **Precision × Recall** (F1 score)

8. **Session-Specific Optimization** - Run threshold sweep per session
   - Test if OVERLAP/LONDON should use 220% vs ASIAN 280%
   - Compare F1 scores across sessions

### Phase 3: Implementation (AC: 9-11)

9. **Configuration Updates** - Implement optimized thresholds in config
   - Update `backend/config/volume_thresholds.yaml` (or create if not exists)
   - Session-aware thresholds: `forex_utad_min_volume_by_session`
   - Add comment explaining optimization results

10. **A/B Testing Mode** (Optional) - Test new thresholds with 10% of live traffic
    - Flag signals generated with new thresholds: `experimental_threshold=True`
    - Compare signal quality over 2 weeks before full rollout

11. **Monitoring Dashboard Update** - Add UTAD threshold metrics to dashboard (Story 9.2)
    - Chart: UTAD pass rate by session (7-day rolling average)
    - Alert: If pass rate drops below 5% or exceeds 25% (indicates threshold miscalibration)

### Phase 4: Documentation & Validation (AC: 12-14)

12. **Analysis Report** - Document optimization findings
    - File: `docs/analysis/forex-utad-threshold-optimization-2025.md`
    - Include: Session-specific recommendations, backtesting results, rationale
    - Reference Wyckoff principles and crew recommendations

13. **Unit Tests** - Verify new threshold behavior
    - Test: UTAD with 2.2x volume passes in OVERLAP session (if 220% threshold chosen)
    - Test: UTAD with 2.2x volume fails in ASIAN session (if 280% threshold remains)
    - Test: Near-miss logging still triggers in new threshold ranges

14. **Integration Test** - End-to-end validation with new thresholds
    - Test: Historical UTAD patterns re-validated with new thresholds
    - Test: Verify precision/recall improvements in test dataset

---

## Tasks / Subtasks

### Phase 1: Data Collection & Analysis (8 hours)

- [ ] Create log analysis script - **2 hours**
  - [ ] Create file: `backend/scripts/analyze_forex_utad_near_misses.py`
  - [ ] Import required libraries:
    - `import pandas as pd`
    - `import json`
    - `from datetime import datetime, timedelta, timezone`
    - `from pathlib import Path`
    - `from typing import Dict, List, Tuple`
  - [ ] Implement `load_production_logs(start_date: datetime, end_date: datetime) -> pd.DataFrame`:
    - Query log storage (e.g., Elasticsearch, CloudWatch, or local JSON logs)
    - Filter for `event="forex_utad_near_miss"`
    - Extract fields: timestamp, symbol, volume_ratio, threshold, session
    - Return as pandas DataFrame
  - [ ] Implement `analyze_by_session(df: pd.DataFrame) -> pd.DataFrame`:
    - Group by `session` (ASIAN/LONDON/NY/OVERLAP)
    - Calculate: count, avg_volume_ratio, min_volume_ratio, max_volume_ratio
    - Calculate: rejection_rate = count / (count + passing_utads)
    - Return summary DataFrame
  - [ ] Implement `analyze_by_symbol(df: pd.DataFrame) -> pd.DataFrame`:
    - Group by `symbol` (EUR/USD, GBP/JPY, etc.)
    - Calculate: count, avg_volume_ratio, session_distribution
    - Flag symbols with >10 near-misses (high rejection candidates)
    - Return summary DataFrame
  - [ ] Implement `calculate_percentiles(df: pd.DataFrame) -> Dict[str, float]`:
    - Calculate: 10th, 25th, 50th, 75th, 90th percentiles of volume_ratio
    - Return dict with percentile values
  - [ ] Implement `export_to_csv(df: pd.DataFrame, output_path: Path)`:
    - Export analysis results to CSV for review
  - [ ] Add CLI interface: `python analyze_forex_utad_near_misses.py --days 90 --output results.csv`

- [ ] Run analysis on production data - **1 hour**
  - [ ] Execute script on 90 days of production logs
  - [ ] Generate reports:
    - `forex_utad_near_miss_by_session.csv`
    - `forex_utad_near_miss_by_symbol.csv`
    - `forex_utad_volume_percentiles.json`
  - [ ] Save reports to `docs/analysis/`

- [ ] Review analysis results with Wyckoff crew - **1 hour**
  - [ ] Present findings to William, Victoria, Rachel (via slash commands)
  - [ ] Questions to answer:
    - Are near-miss counts high enough to warrant optimization? (>100 near-misses?)
    - Which sessions show highest rejection rates?
    - Do any symbols show anomalous patterns? (e.g., always at 2.45x)
  - [ ] Document crew recommendations in `docs/analysis/wyckoff-crew-review-utad.md`

### Phase 2: Backtesting Framework (12 hours)

- [ ] Build historical UTAD dataset - **3 hours**
  - [ ] Create file: `backend/scripts/build_utad_backtest_dataset.py`
  - [ ] Implement `fetch_historical_utads(start_date: datetime, end_date: datetime) -> List[Pattern]`:
    - Query database for all UTAD patterns (passed + near-missed)
    - Include patterns from last 12 months
    - Filter: Only patterns with 4+ weeks of post-pattern price data
    - Return list of Pattern objects
  - [ ] Implement `fetch_post_pattern_prices(pattern: Pattern, weeks_after: int = 4) -> List[OHLCVBar]`:
    - Query price data for 4 weeks after pattern bar
    - Return OHLCV bars for outcome analysis
  - [ ] Implement `classify_utad_outcome(pattern: Pattern, price_bars: List[OHLCVBar]) -> Literal["VALID", "FALSE", "NEUTRAL"]`:
    - Calculate range height: `range_height = pattern.trading_range.high - pattern.trading_range.low`
    - Calculate 50% decline target: `decline_target = pattern.utad_high - (0.5 * range_height)`
    - If any bar.low < decline_target within 4 weeks: Return "VALID" (distribution confirmed)
    - If any bar.high > pattern.utad_high within 4 weeks: Return "FALSE" (distribution failed)
    - Else: Return "NEUTRAL" (inconclusive)
  - [ ] Implement `save_dataset(patterns: List[Pattern], outcomes: List[str], output_path: Path)`:
    - Create CSV with: pattern_id, symbol, timestamp, volume_ratio, session, outcome
    - Save to `docs/analysis/utad_backtest_dataset.csv`
  - [ ] Add CLI interface: `python build_utad_backtest_dataset.py --months 12 --output dataset.csv`

- [ ] Implement threshold sweep backtester - **4 hours**
  - [ ] Create file: `backend/scripts/backtest_utad_thresholds.py`
  - [ ] Import required libraries:
    - `import pandas as pd`
    - `from decimal import Decimal`
    - `from sklearn.metrics import precision_score, recall_score, f1_score`
  - [ ] Implement `load_backtest_dataset(csv_path: Path) -> pd.DataFrame`:
    - Load CSV from Phase 2
    - Return DataFrame with all UTAD patterns
  - [ ] Implement `run_threshold_sweep(df: pd.DataFrame, thresholds: List[Decimal]) -> pd.DataFrame`:
    - For each threshold in range [1.8x, 1.9x, 2.0x, 2.1x, 2.2x, 2.3x, 2.4x, 2.5x, 2.6x, 2.7x, 2.8x]:
      - Calculate: patterns_passed = df[df['volume_ratio'] >= threshold]
      - Calculate: true_positives = patterns_passed[patterns_passed['outcome'] == 'VALID'].count()
      - Calculate: false_positives = patterns_passed[patterns_passed['outcome'] == 'FALSE'].count()
      - Calculate: false_negatives = df[(df['volume_ratio'] < threshold) & (df['outcome'] == 'VALID')].count()
      - Calculate: precision = TP / (TP + FP)
      - Calculate: recall = TP / (TP + FN)
      - Calculate: f1_score = 2 * (precision * recall) / (precision + recall)
      - Store: threshold, patterns_passed, precision, recall, f1_score
    - Return DataFrame with sweep results
  - [ ] Implement `run_session_specific_sweep(df: pd.DataFrame, session: str, thresholds: List[Decimal]) -> pd.DataFrame`:
    - Filter df by session
    - Run threshold sweep on session subset
    - Return session-specific results
  - [ ] Implement `find_optimal_threshold(sweep_results: pd.DataFrame) -> Decimal`:
    - Find threshold with highest F1 score
    - If multiple thresholds tie, choose more conservative (higher) one
    - Return optimal threshold
  - [ ] Implement `plot_threshold_curves(sweep_results: pd.DataFrame, output_path: Path)`:
    - Create matplotlib chart: X-axis = threshold, Y-axis = precision/recall/F1
    - Save chart to `docs/analysis/utad_threshold_optimization_curves.png`
  - [ ] Add CLI interface: `python backtest_utad_thresholds.py --dataset dataset.csv --output results.csv`

- [ ] Run backtest analysis - **2 hours**
  - [ ] Execute threshold sweep on full dataset:
    - `python backtest_utad_thresholds.py --dataset utad_backtest_dataset.csv --output utad_threshold_sweep_results.csv`
  - [ ] Execute session-specific sweeps:
    - `python backtest_utad_thresholds.py --dataset utad_backtest_dataset.csv --session OVERLAP --output utad_threshold_sweep_overlap.csv`
    - Repeat for LONDON, NY, ASIAN
  - [ ] Generate optimization charts
  - [ ] Save all results to `docs/analysis/`

- [ ] Review backtest results with Wyckoff crew - **3 hours**
  - [ ] Present findings to William, Victoria, Rachel
  - [ ] Questions to answer:
    - What is optimal threshold per session? (e.g., OVERLAP: 220%, ASIAN: 280%)
    - Does precision/recall tradeoff make sense from Wyckoff perspective?
    - Are we seeing valid UTAD patterns at 200-220% range?
    - Should we implement session-specific thresholds or keep uniform?
  - [ ] Document crew recommendations in `docs/analysis/wyckoff-crew-backtest-review.md`
  - [ ] Get approval from all three specialists before implementation

### Phase 3: Implementation (6 hours)

- [ ] Create volume threshold configuration file - **1 hour**
  - [ ] Create file: `backend/config/volume_thresholds.yaml`
  - [ ] Define stock thresholds (unchanged from Story 0.2):
    ```yaml
    stock:
      spring_max_volume: 0.70  # 70%
      sos_min_volume: 1.50     # 150%
      utad_min_volume: 2.00    # 200%
      lps_max_volume: 0.85     # 85%
    ```
  - [ ] Define forex baseline thresholds (unchanged from Story 8.3.1):
    ```yaml
    forex:
      spring_max_volume: 0.85  # 85%
      sos_min_volume: 1.80     # 180%
      utad_min_volume: 2.50    # 250% (BASELINE - may be overridden by session)
      lps_max_volume: 1.00     # 100%
    ```
  - [ ] Define forex session-specific overrides (NEW - based on backtest results):
    ```yaml
    forex_session_overrides:
      OVERLAP:
        utad_min_volume: 2.20  # 220% (high liquidity → lower threshold)
        # Rationale: Backtest F1 score 0.85 vs baseline 0.78
      LONDON:
        utad_min_volume: 2.30  # 230% (high liquidity → lower threshold)
        # Rationale: Backtest F1 score 0.82 vs baseline 0.78
      NY:
        utad_min_volume: 2.40  # 240% (moderate adjustment)
        # Rationale: Backtest F1 score 0.80 vs baseline 0.78
      ASIAN:
        utad_min_volume: 2.80  # 280% (low liquidity → stricter threshold)
        # Rationale: Backtest shows higher false positive rate at 250%
    ```
  - [ ] Add comments explaining optimization:
    ```yaml
    # UTAD Threshold Optimization (Story 9.1)
    # Date: 2025-03-15
    # Analysis: 90 days production data + 12 months backtest
    # Crew Approval: William, Victoria, Rachel (see docs/analysis/)
    ```

- [ ] Update VolumeValidator to load session-specific thresholds - **2 hours**
  - [ ] Modify `backend/src/signal_generator/validators/volume_validator.py`:
  - [ ] Add method: `def _load_volume_thresholds_from_config() -> dict`:
    - Load `backend/config/volume_thresholds.yaml`
    - Parse YAML into dict
    - Return thresholds
  - [ ] Update `_get_forex_threshold()` method (lines 330-370):
    - Check if `forex_session_overrides` exists in config
    - If session-specific override exists for UTAD: Use it
    - Else: Use baseline forex threshold
    - Example logic:
      ```python
      if pattern_type == "UTAD" and threshold_type == "min":
          # Check for session-specific override (Story 9.1)
          overrides = config.get("forex_session_overrides", {})
          session_name = context.forex_session.value if context.forex_session else "OVERLAP"
          session_override = overrides.get(session_name, {})

          if "utad_min_volume" in session_override:
              logger.debug(
                  "forex_utad_session_override_applied",
                  session=session_name,
                  baseline_threshold=float(config.forex_utad_min_volume),
                  override_threshold=float(session_override["utad_min_volume"]),
              )
              return Decimal(str(session_override["utad_min_volume"]))

          # Fall back to baseline
          return config.forex_utad_min_volume
      ```
  - [ ] Update near-miss logging to reflect new thresholds:
    - Change note to: `"UTAD rejected but would pass at {alternative_threshold} threshold"`

- [ ] Update tests with new threshold behavior - **2 hours**
  - [ ] Update `test_volume_validator_forex.py`:
    - [ ] Add test: `test_forex_utad_overlap_session_lower_threshold()`:
      - UTAD with 2.2x volume in OVERLAP session
      - Expected: PASS (if 220% threshold chosen)
    - [ ] Add test: `test_forex_utad_asian_session_stricter_threshold()`:
      - UTAD with 2.2x volume in ASIAN session
      - Expected: FAIL (if 280% threshold chosen)
    - [ ] Add test: `test_forex_utad_session_override_logging()`:
      - Verify logger.debug called with "forex_utad_session_override_applied"
    - [ ] Update existing UTAD tests to use explicit sessions
  - [ ] Create integration test: `test_utad_threshold_optimization_integration.py`:
    - [ ] Test: Run historical UTAD dataset through updated validator
    - [ ] Verify: Pass rate matches backtest predictions (±5%)
    - [ ] Verify: Precision/recall metrics match backtest results

- [ ] A/B testing mode (OPTIONAL - if time allows) - **1 hour**
  - [ ] Add feature flag to config: `ENABLE_UTAD_THRESHOLD_AB_TEST: bool = False`
  - [ ] Add flag to ValidationResult: `experimental_threshold: bool = False`
  - [ ] If A/B test enabled:
    - Randomly assign 10% of UTAD patterns to use new thresholds
    - Flag signals with `experimental_threshold=True`
    - Log both old and new threshold results for comparison
  - [ ] Monitor for 2 weeks before full rollout

### Phase 4: Documentation & Validation (4 hours)

- [ ] Write optimization analysis report - **2 hours**
  - [ ] Create file: `docs/analysis/forex-utad-threshold-optimization-2025.md`
  - [ ] Document:
    - [ ] Executive Summary: Key findings and recommendations
    - [ ] Data Collection: Near-miss analysis over 90 days
    - [ ] Backtest Methodology: Dataset construction, threshold sweep approach
    - [ ] Results: Session-specific optimal thresholds
    - [ ] Wyckoff Crew Review: Quotes from William, Victoria, Rachel
    - [ ] Implementation Plan: Configuration changes, test strategy
    - [ ] Expected Impact: Projected increase in UTAD signal generation (e.g., +15%)
    - [ ] Monitoring Plan: Metrics to track post-deployment
  - [ ] Include charts:
    - Near-miss distribution by session (bar chart)
    - Threshold optimization curves (precision/recall/F1 vs threshold)
    - Session-specific backtest results (comparison table)

- [ ] Update Story 8.3.1 documentation - **30 minutes**
  - [ ] Add section to `docs/stories/epic-8/8.3.1.forex-volume-validation-adjustments.md`:
    ```markdown
    ## Post-Deployment Optimization (Story 9.1)

    After 3 months of production data (Dec 2025 - Feb 2026), UTAD thresholds were optimized:

    - **OVERLAP:** 250% → 220% (F1 improvement: 0.78 → 0.85)
    - **LONDON:** 250% → 230% (F1 improvement: 0.78 → 0.82)
    - **NY:** 250% → 240% (F1 improvement: 0.78 → 0.80)
    - **ASIAN:** 250% → 280% (Reduced false positives)

    See [Story 9.1](../epic-9/9.1.forex-utad-threshold-optimization.md) for full analysis.
    ```

- [ ] Create monitoring dashboard section (for Story 9.2) - **1 hour**
  - [ ] Define metrics to track:
    - [ ] UTAD pass rate by session (7-day rolling average)
    - [ ] UTAD near-miss count by session (weekly)
    - [ ] UTAD precision (% of signals that led to valid distribution)
    - [ ] UTAD recall (% of valid distributions that generated signals)
  - [ ] Document in `docs/analysis/utad-threshold-monitoring-plan.md`
  - [ ] Create alert rules:
    - Alert if OVERLAP UTAD pass rate < 8% (threshold too strict)
    - Alert if ASIAN UTAD pass rate > 12% (threshold too loose)

- [ ] Final Wyckoff crew approval - **30 minutes**
  - [ ] Present complete implementation to William, Victoria, Rachel
  - [ ] Get sign-off from all three specialists
  - [ ] Document approval in story notes

---

## Non-Functional Requirements

### Performance
- **Log Analysis:** Script must process 90 days of logs in <5 minutes (assuming 10K log entries/day)
- **Backtest Execution:** Threshold sweep on 1000 patterns must complete in <2 minutes
- **Configuration Load:** YAML parsing must complete in <100ms (one-time load at startup)

### Data Quality
- **Minimum Sample Size:** Require ≥100 near-miss events before optimization (else defer story)
- **Backtest Dataset:** Require ≥500 historical UTAD patterns with outcomes (else expand date range)
- **Statistical Significance:** Require ≥30 patterns per session for session-specific optimization

### Risk Management
- **Conservative Bias:** If backtest results are inconclusive (F1 difference <0.05), keep current thresholds
- **Rollback Plan:** Document how to revert to Story 8.3.1 thresholds if new thresholds underperform
- **Monitoring Period:** Track new thresholds for 4 weeks post-deployment before declaring success

---

## Technical Design

### Data Flow

```
Production Logs (90 days)
    ↓
[analyze_forex_utad_near_misses.py]
    ↓
Near-Miss Statistics (CSV)
    ↓
[Wyckoff Crew Review] → Recommendations
    ↓
Historical Pattern Database (12 months)
    ↓
[build_utad_backtest_dataset.py]
    ↓
UTAD Dataset with Outcomes (CSV)
    ↓
[backtest_utad_thresholds.py]
    ↓
Threshold Sweep Results (Precision/Recall/F1)
    ↓
[Wyckoff Crew Review] → Optimal Thresholds
    ↓
volume_thresholds.yaml (Session-Specific Config)
    ↓
[VolumeValidator._get_forex_threshold()]
    ↓
Updated UTAD Validation (Production)
    ↓
[Monitoring Dashboard - Story 9.2]
```

### Configuration Schema

**File:** `backend/config/volume_thresholds.yaml`

```yaml
# Stock Volume Thresholds (Story 0.2)
stock:
  spring_max_volume: 0.70
  sos_min_volume: 1.50
  utad_min_volume: 2.00
  lps_max_volume: 0.85

# Forex Baseline Thresholds (Story 8.3.1)
forex:
  spring_max_volume: 0.85
  sos_min_volume: 1.80
  utad_min_volume: 2.50  # Baseline (may be overridden by session)
  lps_max_volume: 1.00

# Forex Session-Specific Overrides (Story 9.1)
forex_session_overrides:
  OVERLAP:
    utad_min_volume: 2.20  # Example - actual value from backtest
  LONDON:
    utad_min_volume: 2.30
  NY:
    utad_min_volume: 2.40
  ASIAN:
    utad_min_volume: 2.80

# Optimization Metadata
optimization_metadata:
  date_analyzed: "2025-03-15"
  data_range: "2024-12-01 to 2025-02-28"
  crew_approval: ["William", "Victoria", "Rachel"]
  story_reference: "9.1.forex-utad-threshold-optimization"
```

---

## Testing Strategy

### Unit Tests (2 hours)

**File:** `backend/tests/unit/signal_generator/validators/test_volume_validator_utad_optimization.py`

```python
@pytest.mark.asyncio
async def test_forex_utad_overlap_session_lower_threshold():
    """Test: UTAD with 2.2x volume passes in OVERLAP session (220% threshold)."""
    context = create_forex_validation_context(
        pattern_type="UTAD",
        volume_ratio=Decimal("2.20"),
        forex_session=ForexSession.OVERLAP,
    )

    result = await volume_validator.validate(context)

    assert result.status == ValidationStatus.PASS
    assert result.metadata["threshold"] == 2.20

@pytest.mark.asyncio
async def test_forex_utad_asian_session_stricter_threshold():
    """Test: UTAD with 2.2x volume fails in ASIAN session (280% threshold)."""
    context = create_forex_validation_context(
        pattern_type="UTAD",
        volume_ratio=Decimal("2.20"),
        forex_session=ForexSession.ASIAN,
    )

    result = await volume_validator.validate(context)

    assert result.status == ValidationStatus.FAIL
    assert "2.80" in result.reason  # Should mention 280% threshold
```

### Integration Tests (1 hour)

**File:** `backend/tests/integration/signal_generator/test_utad_threshold_optimization_integration.py`

```python
@pytest.mark.asyncio
async def test_utad_backtest_dataset_validation():
    """Test: Historical UTAD dataset re-validated with new thresholds."""
    # Load backtest dataset
    dataset = pd.read_csv("docs/analysis/utad_backtest_dataset.csv")

    # Re-validate all patterns with new thresholds
    results = []
    for _, row in dataset.iterrows():
        context = build_context_from_row(row)
        result = await volume_validator.validate(context)
        results.append(result.status)

    # Calculate actual pass rate
    actual_pass_rate = sum(1 for r in results if r == ValidationStatus.PASS) / len(results)

    # Compare to backtest predictions (should be within ±5%)
    expected_pass_rate = 0.15  # Example from backtest
    assert abs(actual_pass_rate - expected_pass_rate) < 0.05
```

---

## Dependencies

### Required Stories (Must Be Complete)
- ✅ Story 8.3.1 - Forex Volume Validation (provides near-miss logging)
- ✅ Story 8.5 - Level Validation (provides UTAD level detection)

### Optional Dependencies (Nice-to-Have)
- Story 9.2 - Validation Metrics Dashboard (for post-deployment monitoring)

### External Dependencies
- **Production Logs:** 90 days of forex trading data with near-miss events
- **Historical Patterns:** 12 months of UTAD patterns with 4+ weeks post-pattern price data
- **Wyckoff Crew Availability:** William, Victoria, Rachel for review sessions (4-6 hours total)

---

## Risk Assessment

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Insufficient near-miss data (<100 events) | Medium | High | Defer story 2-3 months if sample size too small |
| Backtest overfitting (optimized for historical data) | Medium | Medium | Use out-of-sample validation (last 3 months excluded from optimization) |
| Session detection inaccuracies | Low | Medium | Verify session classification with forex crew |
| Configuration loading failures | Low | High | Add validation checks + rollback to defaults |

### Business Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| New thresholds increase false positives | Medium | High | Monitor precision metrics for 4 weeks; rollback if precision drops >10% |
| Crew disagrees on optimal thresholds | Low | Medium | Use F1 score as tiebreaker; defer if strong disagreement |
| Market regime change invalidates backtest | Low | High | Re-run analysis every 6 months; update thresholds as needed |

---

## Success Metrics

### Primary Metrics (Must Achieve)
1. **UTAD Signal Generation:** Increase by ≥10% without decreasing precision
2. **Precision (Valid UTADs):** Maintain ≥75% (same as Story 8.3.1 baseline)
3. **Recall (Missed Valid UTADs):** Increase by ≥15% (catch more valid setups)
4. **F1 Score:** Overall improvement ≥0.05 (from baseline ~0.78 to ~0.83+)

### Secondary Metrics (Nice-to-Have)
5. **Session-Specific Pass Rates:** OVERLAP 12-18%, LONDON 10-15%, NY 8-12%, ASIAN 3-6%
6. **Near-Miss Reduction:** Reduce 200-250% range rejections by ≥50%
7. **Trader Satisfaction:** Positive feedback from Wyckoff crew on signal quality

---

## Rollout Plan

### Phase 1: Analysis (Week 1-2)
- Run log analysis scripts
- Generate backtest dataset
- Initial Wyckoff crew review

### Phase 2: Backtesting (Week 3-4)
- Execute threshold sweeps
- Analyze session-specific results
- Final Wyckoff crew approval

### Phase 3: Implementation (Week 5)
- Update configuration
- Modify VolumeValidator
- Write unit/integration tests

### Phase 4: Deployment (Week 6)
- Deploy to staging environment
- Run smoke tests
- Deploy to production with monitoring

### Phase 5: Monitoring (Week 7-10)
- Track precision/recall metrics daily
- Weekly review with Wyckoff crew
- Adjust if needed; declare success after 4 weeks

---

## Related Stories

- **Story 8.3.1** - Forex Volume Validation (provides near-miss logging foundation)
- **Story 9.2** - Validation Metrics Dashboard (provides monitoring infrastructure)
- **Story 9.3** - A/B Testing Framework (future: systematic threshold testing)

---

## Notes

### Wyckoff Crew Quotes (from Story 8.3.1 Review)

**Victoria (Volume Specialist):**
> "UTAD threshold (250%): Potentially too strict. I suggest monitoring rejection rates for 2-3 months and testing 200% vs 250% in backtests."

**Rachel (Risk Manager):**
> "Consider 200-220% after collecting data, but don't rush. Better to miss a few signals than generate false UTADs."

**William (Wyckoff Mentor):**
> "UTAD is about supply climax. If we see consistent near-misses at 220-240% with valid distribution outcomes, we should lower the threshold. Let the data guide us."

---

## Completion Criteria

- [ ] All acceptance criteria (1-14) met
- [ ] All tasks completed (30 hours estimated)
- [ ] Unit tests passing (100% coverage for new logic)
- [ ] Integration tests passing
- [ ] Wyckoff crew approval (William, Victoria, Rachel)
- [ ] Analysis report published (`docs/analysis/forex-utad-threshold-optimization-2025.md`)
- [ ] Configuration deployed to production
- [ ] Monitoring dashboard updated (Story 9.2)
- [ ] 4-week post-deployment monitoring complete
- [ ] Success metrics achieved (10% signal increase, <10% precision drop)

---

**Story Status:** Ready for Planning
**Next Action:** Schedule kickoff meeting with Wyckoff crew after 90 days of Story 8.3.1 production data
