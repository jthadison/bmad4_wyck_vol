# Story 8.1: Master Orchestrator Architecture

## Status
Ready for Review

## Story
**As an** orchestrator developer,
**I want** to design the master orchestrator that coordinates all detectors and validators,
**so that** signal generation follows a clear, auditable pipeline.

## Acceptance Criteria
1. Class: `MasterOrchestrator` with method `analyze_symbol(symbol, timeframe) -> List[TradeSignal]`
2. Pipeline stages: Data → Volume → Range → Phase → Pattern → Risk → Validation → Signal
3. Event-driven coordination: VolumeAnalyzer emits events, PatternDetectors subscribe
4. Dependency injection: all detectors injected (testable, mockable)
5. Error isolation: detector failures don't crash pipeline, logged and skipped
6. Parallel processing: multiple symbols analyzed concurrently (thread pool)
7. Caching: intermediate results cached (ranges, phases) to avoid recomputation
8. Unit test: mock detectors verify orchestration logic
9. Integration test: full pipeline with real data generates signals
10. Performance: analyze 10 symbols with 500 bars each in <5 seconds

## Tasks / Subtasks

- [x] Design event bus architecture for detector coordination (AC: 3)
  - [x] Create event types: `BarIngested`, `VolumeAnalyzed`, `RangeDetected`, `PhaseDetected`, `PatternDetected`
  - [x] Define event base class with: `event_type: str`, `timestamp: datetime`, `correlation_id: UUID`, `data: dict`
  - [x] Implement in-memory event bus in `backend/src/orchestrator/event_bus.py`
  - [x] Add methods: `subscribe(event_type, handler)`, `publish(event)`, `unsubscribe(event_type, handler)`
  - [x] Use asyncio queues for async event processing
  - [x] Add structured logging for all event publishes/subscribes

- [x] Create dependency injection container (AC: 4)
  - [x] Create file: `backend/src/orchestrator/container.py`
  - [x] Define `OrchestratorContainer` class with lazy-loaded dependencies
  - [x] Load all detectors from previous stories:
    - Volume detectors (Stories 2.1-2.4)
    - Range detectors (Stories 3.1-3.7)
    - Phase detectors (Stories 4.1-4.7)
    - Pattern detectors (Stories 5.1-5.6, 6.1-6.7)
    - Risk manager (Story 7.8)
  - [x] Implement factory methods for each detector with configuration
  - [x] Add health check method to verify all dependencies initialized
  - [x] Support mock/test implementations via configuration flag

- [x] Create pipeline stage abstraction (AC: 2)
  - [x] Create file: `backend/src/orchestrator/pipeline_stage.py`
  - [x] Define `PipelineStage` abstract base class
  - [x] Required methods: `async process(input_data, context) -> StageResult`
  - [x] StageResult dataclass: `success: bool`, `output: Any`, `error: str | None`, `execution_time_ms: float`
  - [x] Add timing decorator for automatic execution time tracking
  - [x] Add structured logging with stage name and correlation_id

- [x] Implement caching layer for intermediate results (AC: 7)
  - [x] Create file: `backend/src/orchestrator/cache.py`
  - [x] Define `OrchestratorCache` class with TTL-based expiration
  - [x] Cache keys: `trading_ranges_{symbol}_{timeframe}`, `phases_{symbol}_{timeframe}`, `volume_analysis_{symbol}_{timeframe}`
  - [x] Use Python `cachetools` library with LRU eviction policy
  - [x] Default TTL: 300 seconds (5 minutes) for intermediate results
  - [x] Add cache invalidation on new bar ingestion
  - [x] Add cache hit/miss metrics for monitoring

- [x] Create MasterOrchestrator core class (AC: 1)
  - [x] Create file: `backend/src/orchestrator/master_orchestrator.py`
  - [x] Define `MasterOrchestrator` class with dependency injection
  - [x] Initialize event bus, container, cache in `__init__`
  - [x] Add correlation_id generation for request tracing
  - [x] Register all detector event subscriptions
  - [x] Add structured logging with orchestrator lifecycle events

- [x] Implement Stage 1: Data ingestion (AC: 2)
  - [x] Create method: `async _fetch_bars(symbol: str, timeframe: str, lookback: int) -> List[OHLCVBar]`
  - [x] Call market data service to fetch OHLCV bars
  - [x] Default lookback: 500 bars (sufficient for pattern detection)
  - [x] Validate bars: non-empty, chronological, no gaps
  - [x] Publish `BarIngested` event for each bar
  - [x] Return bars sorted by timestamp ascending

- [x] Implement Stage 2: Volume analysis (AC: 2)
  - [x] Create method: `async _analyze_volume(bars: List[OHLCVBar]) -> VolumeAnalysis`
  - [x] Check cache for existing volume analysis
  - [x] If cache miss, call volume analyzers from Stories 2.1-2.4:
    - `calculate_volume_ratio()` (Story 2.1)
    - `calculate_spread_ratio()` (Story 2.2)
    - `analyze_close_position()` (Story 2.3)
    - `classify_effort_result()` (Story 2.4)
  - [x] Aggregate results into VolumeAnalysis dataclass
  - [x] Cache result with TTL
  - [x] Publish `VolumeAnalyzed` event

- [x] Implement Stage 3: Trading range detection (AC: 2)
  - [x] Create method: `async _detect_trading_ranges(bars: List[OHLCVBar], volume_analysis: VolumeAnalysis) -> List[TradingRange]`
  - [x] Check cache for existing trading ranges
  - [x] If cache miss, call range detectors from Stories 3.1-3.7:
    - Pivot detection (Story 3.1)
    - Range clustering (Story 3.2)
    - Range quality scoring (Story 3.3)
    - Creek calculation (Story 3.4)
    - Ice calculation (Story 3.5)
    - Jump calculation (Story 3.6)
    - Supply/demand mapping (Story 3.7)
  - [x] Filter ranges by quality score ≥60 (FR9)
  - [x] Cache active trading ranges with TTL
  - [x] Publish `RangeDetected` event for each valid range

- [x] Implement Stage 4: Phase detection (AC: 2)
  - [x] Create method: `async _detect_phases(bars: List[OHLCVBar], trading_ranges: List[TradingRange], volume_analysis: VolumeAnalysis) -> List[Phase]`
  - [x] Check cache for existing phase data
  - [x] If cache miss, call phase detectors from Stories 4.1-4.7:
    - Selling Climax (Story 4.1)
    - Automatic Rally (Story 4.2)
    - Secondary Test (Story 4.3)
    - Phase classification (Story 4.4)
    - Phase confidence scoring (Story 4.5)
    - Phase progression validation (Story 4.6)
  - [x] Validate phase confidence ≥70% (FR3)
  - [x] Cache phase data with TTL
  - [x] Publish `PhaseDetected` event

- [x] Implement Stage 5: Pattern detection (AC: 2, 3)
  - [x] Create method: `async _detect_patterns(bars: List[OHLCVBar], trading_ranges: List[TradingRange], phases: List[Phase], volume_analysis: VolumeAnalysis) -> List[Pattern]`
  - [x] Call pattern detectors based on current phase:
    - Spring detector (Stories 5.1-5.6) - Phase C only
    - SOS/LPS detector (Stories 6.1-6.7) - Phase D primary, late Phase C if confidence 85+
  - [x] Each detector subscribes to relevant events
  - [x] Validate patterns against volume requirements (FR12)
  - [x] Validate phase-pattern alignment (FR15)
  - [x] Collect all detected patterns
  - [x] Publish `PatternDetected` event for each pattern

- [x] Implement Stage 6: Risk validation (AC: 2)
  - [x] Create method: `async _validate_risk(patterns: List[Pattern], portfolio_context: PortfolioContext) -> List[Tuple[Pattern, PositionSizing | None]]`
  - [x] For each pattern, create preliminary signal
  - [x] Call RiskManager.validate_and_size() from Story 7.8
  - [x] Collect approved patterns with PositionSizing
  - [x] Log rejected patterns with rejection reasons
  - [x] Implement rejection categorization with stage tracking (Team Review: Rachel)
    - Track which validation stage failed (pattern_risk, r_multiple, portfolio_heat, etc.)
    - Record threshold vs actual values for near-miss analysis
    - Enable campaign-level rejection aggregation for learning
  - [x] Return list of (pattern, position_sizing) tuples

- [x] Implement Stage 7: Signal generation (AC: 1, 2)
  - [x] Create method: `async _generate_signals(validated_patterns: List[Tuple[Pattern, PositionSizing]]) -> List[TradeSignal]`
  - [x] For each validated pattern with approved position sizing:
    - Create TradeSignal dataclass (from Story 8.8)
    - Populate: symbol, pattern_type, phase, entry_price, stop_loss, target_levels, position_size, risk_amount, r_multiple
    - Add confidence_score, campaign_id, validation_chain
    - Add timestamp and correlation_id
  - [x] Persist signals to database via signal repository
  - [x] Publish SignalGenerated events
  - [x] Return list of generated signals

- [x] Implement main analyze_symbol method (AC: 1, 2)
  - [x] Signature: `async def analyze_symbol(symbol: str, timeframe: str) -> List[TradeSignal]`
  - [x] Generate correlation_id for request tracing
  - [x] Execute pipeline stages sequentially:
    1. Fetch bars
    2. Analyze volume
    3. Detect trading ranges
    4. Detect phases
    5. Detect patterns
    6. Validate risk
    7. Generate signals
  - [x] Wrap each stage in try/except for error isolation (AC: 5)
  - [x] Log stage completion with execution time
  - [x] Return list of generated signals (may be empty if no patterns detected)

- [x] Add error isolation and resilience (AC: 5)
  - [x] Wrap each detector call in try/except
  - [x] Log detector failures with full context: detector_name, symbol, error, stack_trace
  - [x] Continue pipeline on individual detector failure (don't crash entire analysis)
  - [x] Track failed detectors in StageResult
  - [x] Add circuit breaker pattern for consistently failing detectors
  - [x] Emit `DetectorFailed` event for monitoring

- [x] Implement parallel symbol processing (AC: 6)
  - [x] Create method: `async def analyze_symbols(symbols: List[str], timeframe: str) -> Dict[str, List[TradeSignal]]`
  - [x] Use asyncio.gather() to analyze symbols concurrently
  - [x] Add semaphore to limit concurrency (default: 10 symbols)
  - [x] Collect results into dictionary: {symbol: [signals]}
  - [x] Log aggregate metrics: total_symbols, total_signals, total_time
  - [x] Handle individual symbol failures without affecting others

- [x] Build portfolio context for risk validation
  - [x] Create method: `async _build_portfolio_context() -> PortfolioContext`
  - [x] Fetch account equity from portfolio service
  - [x] Fetch open positions from position repository
  - [x] Fetch active campaigns from campaign repository
  - [x] Load sector mappings from configuration
  - [x] Load correlation config from configuration
  - [x] Return PortfolioContext dataclass (from Story 7.8)

- [x] Add structured logging throughout (Architecture requirement)
  - [x] Log orchestrator initialization: loaded_detectors, cache_config
  - [x] Log pipeline start: symbol, timeframe, correlation_id
  - [x] Log each stage: stage_name, execution_time_ms, success/failure
  - [x] Log pattern detection: pattern_type, confidence, phase
  - [x] Log risk validation: approved/rejected, rejection_reason
  - [x] Log signal generation: signal_count, symbols_analyzed
  - [x] Use structlog with consistent field names

- [x] Write unit tests with mock detectors (AC: 8)
  - [x] Create test file: `backend/tests/unit/orchestrator/test_master_orchestrator.py`
  - [x] Create mock detector fixtures
  - [x] Test analyze_symbol with mocked pipeline stages
  - [x] Test error isolation: detector failure doesn't crash pipeline
  - [x] Test cache hit/miss scenarios
  - [x] Test event bus publish/subscribe
  - [x] Test parallel symbol processing
  - [x] Verify correlation_id propagation through pipeline

- [x] Write integration tests with real data (AC: 9)
  - [x] Create test file: `backend/tests/integration/orchestrator/test_full_pipeline.py`
  - [x] Load historical OHLCV data for AAPL (1 year, daily timeframe)
  - [x] Run full pipeline with real detectors
  - [x] Verify known patterns are detected (use labeled dataset)
  - [x] Verify signals generated for valid patterns
  - [x] Verify rejected patterns logged with reasons
  - [x] Check end-to-end execution time
  - [x] Validate all signals have required fields (FR22)

- [x] Write performance benchmarks (AC: 10)
  - [x] Create test file: `backend/tests/integration/orchestrator/test_performance.py`
  - [x] Generate synthetic OHLCV data: 10 symbols × 500 bars each
  - [x] Measure analyze_symbols() execution time
  - [x] Assert: total time <5 seconds (AC: 10)
  - [x] Measure per-symbol average time
  - [x] Measure per-stage average time
  - [x] Log performance breakdown: data_fetch, volume_analysis, range_detection, phase_detection, pattern_detection, risk_validation, signal_generation
  - [x] Track cache hit rates and performance impact

- [x] Add health check endpoint (Integration)
  - [x] Update `backend/src/api/routes/health.py`
  - [x] Add endpoint: `GET /api/v1/health/orchestrator`
  - [x] Check MasterOrchestrator initialization status
  - [x] Verify all detectors loaded successfully
  - [x] Check event bus status
  - [x] Return health status: healthy/degraded/unhealthy
  - [x] Include detector health: {detector_name: status}

- [x] Create orchestrator service integration (Integration)
  - [x] Create file: `backend/src/orchestrator/service.py`
  - [x] Instantiate MasterOrchestrator as singleton
  - [x] Expose analyze_symbol and analyze_symbols methods
  - [x] Add FastAPI dependency for injection into routes
  - [x] Initialize orchestrator on application startup
  - [x] Add graceful shutdown cleanup

## Dev Notes

### Previous Story Insights

**From Story 7.8 (RiskManager Module Integration):**
- RiskManager provides unified risk validation via `validate_and_size(signal, portfolio_context) -> PositionSizing | None`
- Validation pipeline: pattern risk → R-multiple → position size → portfolio heat → campaign risk → correlated risk
- Returns None with rejection_reason if any validation fails
- Returns PositionSizing with full validation history if all pass
- Thread-safe with asyncio.Lock for concurrent validation
- Performance target: <10ms per validation
- Located at: `backend/src/risk_management/risk_manager.py`

**Key Integration Point:** MasterOrchestrator will call RiskManager for each detected pattern before signal generation.

**Pattern Detection Stories (Epics 2-6):**
- Epic 2: Volume analysis (volume_ratio, spread_ratio, effort/result classification)
- Epic 3: Trading range detection (pivots, clustering, Creek/Ice/Jump levels)
- Epic 4: Phase detection (SC, AR, ST, phase classification with confidence)
- Epic 5: Spring pattern detection (spring detection, volume validation, test confirmation)
- Epic 6: SOS/LPS detection (breakout detection, volume validation, LPS detection)

**Key Insight:** All detector modules from previous epics must be coordinated by the orchestrator in correct sequence with proper event propagation.

### Data Models

**Event Base Model** [New for this story]

Create in `backend/src/orchestrator/events.py`:

```python
from datetime import datetime, timezone
from uuid import UUID, uuid4
from pydantic import BaseModel, Field
from typing import Any, Literal

class Event(BaseModel):
    """Base class for all orchestrator events."""
    event_id: UUID = Field(default_factory=uuid4)
    event_type: str = Field(..., description="Type of event")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    correlation_id: UUID = Field(..., description="Request correlation ID for tracing")
    symbol: str = Field(..., max_length=20)
    timeframe: str = Field(...)
    data: dict[str, Any] = Field(default_factory=dict, description="Event-specific data")

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat()}

class BarIngestedEvent(Event):
    """Emitted when OHLCV bar is ingested."""
    event_type: Literal["bar_ingested"] = "bar_ingested"
    bar_timestamp: datetime

class VolumeAnalyzedEvent(Event):
    """Emitted when volume analysis completes."""
    event_type: Literal["volume_analyzed"] = "volume_analyzed"
    volume_ratio: float
    spread_ratio: float
    close_position: float  # 0.0-1.0 position within bar (Team Review: Victoria)
    effort_result: str     # "harmony", "divergence_bullish", "divergence_bearish" (Team Review: Victoria)

class RangeDetectedEvent(Event):
    """Emitted when trading range is detected."""
    event_type: Literal["range_detected"] = "range_detected"
    range_id: UUID
    creek: float
    ice: float
    jump: float

class PhaseDetectedEvent(Event):
    """Emitted when Wyckoff phase is detected."""
    event_type: Literal["phase_detected"] = "phase_detected"
    phase: str
    confidence: int

class PatternDetectedEvent(Event):
    """Emitted when pattern is detected."""
    event_type: Literal["pattern_detected"] = "pattern_detected"
    pattern_id: UUID
    pattern_type: str
    confidence_score: int
```

**StageResult Model** [New for this story]

Create in `backend/src/orchestrator/pipeline_stage.py`:

```python
from dataclasses import dataclass
from typing import Any

@dataclass
class StageResult:
    """Result from a pipeline stage execution."""
    success: bool
    output: Any
    error: str | None = None
    execution_time_ms: float = 0.0
    warnings: list[str] = None

    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []
```

**OrchestratorConfig Model** [New for this story]

Create in `backend/src/orchestrator/config.py`:

```python
from pydantic_settings import BaseSettings
from typing import Literal

class OrchestratorConfig(BaseSettings):
    """Configuration for MasterOrchestrator."""

    # Pipeline settings
    default_lookback_bars: int = 500
    max_concurrent_symbols: int = 10

    # Cache settings
    cache_ttl_seconds: int = 300  # 5 minutes
    cache_max_size: int = 1000

    # Performance settings
    enable_parallel_processing: bool = True
    enable_caching: bool = True

    # Error handling
    max_detector_retries: int = 3
    circuit_breaker_threshold: int = 5  # failures before circuit opens

    # Detector modes
    detector_mode: Literal["production", "test", "mock"] = "production"

    class Config:
        env_prefix = "ORCHESTRATOR_"
```

### Architecture Context

**Event-Driven Coordination** [Source: architecture/2-high-level-architecture.md]

From the architecture: "Simplified Async Pattern (FastAPI BackgroundTasks): Pattern detection runs in background tasks triggered by incoming OHLCV data."

The MasterOrchestrator implements this pattern using an in-memory event bus:
- Detectors subscribe to specific event types
- Pipeline stages publish events as they complete
- Event bus routes events to subscribed handlers
- All event handling is async using asyncio
- No external message queue needed for MVP (suitable for 1-50 symbols)

**Pipeline Stage Sequence** [Source: architecture/8-core-workflows.md]

The workflow diagram shows the exact sequence:
```
Polygon.io → Market Data Service → Pattern Engine → Signal Generator → Risk Management
```

MasterOrchestrator implements this as:
1. **Data Stage**: Fetch OHLCV bars from market data service
2. **Volume Stage**: Calculate volume_ratio, spread_ratio (Epic 2)
3. **Range Stage**: Detect trading ranges, calculate Creek/Ice/Jump (Epic 3)
4. **Phase Stage**: Detect Wyckoff phase with confidence (Epic 4)
5. **Pattern Stage**: Run pattern detectors (Spring, SOS, LPS) (Epics 5-6)
6. **Risk Stage**: Validate against risk limits via RiskManager (Epic 7)
7. **Signal Stage**: Generate TradeSignal with all required fields (Story 8.8)

**Dependency Injection** [Source: architecture/10-unified-project-structure.md]

All detector modules are located in structured directories:
```
backend/src/
├── pattern_engine/
│   ├── detectors/
│   │   ├── spring_detector.py
│   │   ├── sos_detector.py
│   │   └── ...
│   └── engine.py
├── risk_management/
│   └── risk_manager.py
└── orchestrator/
    ├── master_orchestrator.py
    ├── container.py  # NEW: Dependency injection
    └── event_bus.py  # NEW: Event coordination
```

OrchestratorContainer loads all detectors at initialization and injects them into MasterOrchestrator.

### File Locations

**Project Structure Reference** [Source: architecture/10-unified-project-structure.md]

Create/modify these files:
```
backend/src/
├── orchestrator/                    # NEW: Orchestrator module
│   ├── __init__.py
│   ├── master_orchestrator.py      # NEW: Core orchestrator class
│   ├── container.py                # NEW: Dependency injection
│   ├── event_bus.py                # NEW: Event coordination
│   ├── events.py                   # NEW: Event models
│   ├── pipeline_stage.py           # NEW: Stage abstraction
│   ├── cache.py                    # NEW: Result caching
│   ├── config.py                   # NEW: Configuration
│   └── service.py                  # NEW: Service integration
├── api/routes/
│   └── health.py                   # MODIFY: Add orchestrator health
└── models/
    └── trade_signal.py             # NEW: TradeSignal model (Story 8.8)
```

Test files:
```
backend/tests/
├── unit/orchestrator/
│   ├── test_master_orchestrator.py # NEW: Unit tests with mocks
│   ├── test_event_bus.py           # NEW: Event bus tests
│   ├── test_cache.py               # NEW: Cache tests
│   └── test_pipeline_stage.py      # NEW: Stage abstraction tests
└── integration/orchestrator/
    ├── test_full_pipeline.py       # NEW: End-to-end pipeline test
    └── test_performance.py         # NEW: Performance benchmarks
```

### API Specifications

**No New Public Endpoints** [Source: architecture/5-api-specification.md]

MasterOrchestrator is an internal service. However, it integrates with existing endpoints:

**Existing Signal Endpoints:**
- `GET /api/v1/signals` - Returns signals generated by orchestrator
- `GET /api/v1/signals/{signal_id}` - Returns individual signal with validation history
- `WebSocket /ws` - Pushes real-time signals as they're generated

**Enhanced Health Endpoint:**

Add to existing `GET /api/v1/health`:

```json
{
  "status": "healthy",
  "components": {
    "orchestrator": {
      "status": "healthy",
      "detectors_loaded": 13,
      "failed_detectors": [],
      "cache_hit_rate": 0.85,
      "avg_analysis_time_ms": 450
    }
  }
}
```

### Integration Notes

**BackgroundTasks Integration** [Source: architecture/2-high-level-architecture.md]

From architecture: "Pattern detection runs in background tasks triggered by incoming OHLCV data."

Integration with FastAPI BackgroundTasks:

```python
from fastapi import BackgroundTasks

@router.post("/api/v1/bars")
async def ingest_bar(bar: OHLCVBar, background_tasks: BackgroundTasks):
    # Persist bar
    await ohlcv_repository.save(bar)

    # Trigger orchestrator analysis in background
    background_tasks.add_task(
        orchestrator.analyze_symbol,
        symbol=bar.symbol,
        timeframe=bar.timeframe
    )

    return {"status": "ingested"}
```

**WebSocket Integration** [Source: architecture/8-core-workflows.md]

Orchestrator publishes signals to WebSocket clients:

```python
async def _generate_signals(...) -> List[TradeSignal]:
    for signal in signals:
        await signal_repository.save(signal)

        # Publish to WebSocket clients
        await websocket_manager.broadcast({
            "type": "signal_generated",
            "data": signal.model_dump_json()
        })

    return signals
```

### Testing Requirements

**Testing Framework** [Source: architecture/12-testing-strategy.md]
- Backend testing: pytest (8.0+)
- Unit tests: `backend/tests/unit/orchestrator/`
- Integration tests: `backend/tests/integration/orchestrator/`
- Use pytest fixtures for mock detectors
- Use asyncio test support (pytest-asyncio)

**Test Coverage Requirements** [Source: architecture/12-testing-strategy.md]
- Unit test each pipeline stage independently
- Mock all detector dependencies for unit tests
- Integration test with real data from labeled dataset
- Performance test with 10 symbols × 500 bars
- Error isolation test: verify detector failures don't crash pipeline

**Mock Detector Strategy:**

Create pytest fixtures for all detector types:

```python
import pytest
from unittest.mock import AsyncMock

@pytest.fixture
def mock_spring_detector():
    """Mock Spring detector."""
    detector = AsyncMock()
    detector.detect.return_value = [
        Pattern(
            pattern_type="SPRING",
            symbol="AAPL",
            confidence_score=85,
            # ... other fields
        )
    ]
    return detector

@pytest.fixture
def mock_volume_analyzer():
    """Mock Volume analyzer."""
    analyzer = AsyncMock()
    analyzer.analyze.return_value = VolumeAnalysis(
        volume_ratio=0.5,
        spread_ratio=1.2,
        # ... other fields
    )
    return analyzer

@pytest.fixture
def orchestrator_with_mocks(mock_spring_detector, mock_volume_analyzer):
    """MasterOrchestrator with mocked dependencies."""
    container = OrchestratorContainer(mode="test")
    container.spring_detector = mock_spring_detector
    container.volume_analyzer = mock_volume_analyzer
    # ... inject other mocks

    orchestrator = MasterOrchestrator(container=container)
    return orchestrator
```

### Technical Constraints

**Concurrency Model** [Source: architecture/3-tech-stack.md]
- Python 3.11+ with async/await
- FastAPI async endpoints
- asyncio for concurrent symbol processing
- Semaphore to limit concurrent analyses (default: 10)

**Performance Requirements** (AC: 10)
- Analyze 10 symbols × 500 bars in <5 seconds
- Average per-symbol time: <500ms
- Cache hit should reduce analysis time by 60%+

**Breakdown estimation:**
- Data fetch: ~50ms (database query)
- Volume analysis: ~20ms
- Range detection: ~100ms
- Phase detection: ~80ms
- Pattern detection: ~150ms
- Risk validation: ~10ms (from Story 7.8)
- Signal generation: ~10ms
- Total: ~420ms per symbol (within 500ms budget)

**Caching Strategy:**
- Cache trading ranges (most expensive computation)
- Cache phase data (moderate cost)
- Cache volume analysis (inexpensive, but frequently reused)
- Invalidate cache on new bar arrival
- Use LRU eviction with max 1000 entries

**Error Isolation** (AC: 5)
- Wrap each detector in try/except
- Log failures with full context
- Continue pipeline on detector failure
- Track failed detectors for monitoring
- Implement circuit breaker after 5 consecutive failures

### Logging and Observability

**Structured Logging** [Source: architecture/3-tech-stack.md - structlog 24.1+]

Log orchestrator events:

```python
import structlog
logger = structlog.get_logger()

# Pipeline start
logger.info("orchestrator_analysis_start",
            symbol=symbol,
            timeframe=timeframe,
            correlation_id=str(correlation_id))

# Stage completion
logger.debug("pipeline_stage_complete",
             stage="volume_analysis",
             execution_time_ms=25.3,
             success=True,
             correlation_id=str(correlation_id))

# Pattern detection
logger.info("pattern_detected",
            pattern_type="SPRING",
            symbol=symbol,
            confidence=85,
            phase="C",
            correlation_id=str(correlation_id))

# Risk validation
logger.info("risk_validation_complete",
            approved_count=2,
            rejected_count=1,
            rejection_reasons=["Portfolio heat limit exceeded"],
            correlation_id=str(correlation_id))

# Signal generation
logger.info("signals_generated",
            signal_count=2,
            symbols_analyzed=10,
            total_time_ms=4523,
            correlation_id=str(correlation_id))

# Error isolation
logger.error("detector_failure",
             detector="SpringDetector",
             symbol=symbol,
             error=str(exc),
             stack_trace=traceback.format_exc(),
             correlation_id=str(correlation_id))
```

**Distributed Tracing** [Source: architecture/17-monitoring-and-observability.md]

Use OpenTelemetry for pipeline tracing:

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

async def analyze_symbol(self, symbol: str, timeframe: str):
    with tracer.start_as_current_span("orchestrator.analyze_symbol") as span:
        span.set_attribute("symbol", symbol)
        span.set_attribute("timeframe", timeframe)

        with tracer.start_as_current_span("stage.volume_analysis"):
            volume_analysis = await self._analyze_volume(bars)

        with tracer.start_as_current_span("stage.pattern_detection"):
            patterns = await self._detect_patterns(...)

        # ... continue for all stages
```

### Dependencies

**Python Libraries** [Source: architecture/3-tech-stack.md]
- Python 3.11+ (async/await support)
- FastAPI 0.109+ (async web framework, BackgroundTasks)
- asyncio (built-in for concurrency)
- cachetools (LRU caching)
- structlog 24.1+ (structured logging)
- OpenTelemetry 1.22+ (distributed tracing)
- pytest 8.0+ (testing)
- pytest-asyncio (async test support)

**Internal Dependencies**
- Epic 2 Stories: Volume analysis modules
- Epic 3 Stories: Trading range detection modules
- Epic 4 Stories: Phase detection modules
- Epic 5 Stories: Spring pattern detection modules
- Epic 6 Stories: SOS/LPS detection modules
- Story 7.8: RiskManager module
- Story 8.8: TradeSignal model (created in parallel)

**Related Stories**
- Story 8.2: Multi-Stage Validation Workflow (extends orchestrator with validation stages)
- Story 8.8: Trade Signal Output Format (defines TradeSignal model used by orchestrator)
- Story 8.10: MasterOrchestrator Integration (final integration and deployment)

### Risk Mitigation Notes

**Why MasterOrchestrator Matters** [Source: Epic 8 PRD]
- Centralizes all detection and validation logic
- Ensures correct pipeline execution order
- Provides complete audit trail via correlation_id
- Enables systematic testing of entire detection system
- Makes debugging easier (single entry point for analysis)

**Common Integration Pitfalls:**
1. **Incorrect stage ordering**: Fixed by enforcing sequential pipeline
2. **Missing detector coordination**: Solved by event bus with typed events
3. **Detector failures crash system**: Mitigated by error isolation and circuit breakers
4. **Performance degradation**: Addressed by caching and parallel processing
5. **Missing audit trail**: Solved by correlation_id propagation and structured logging

**Event Bus vs Message Queue Decision:**

For MVP, in-memory event bus is sufficient:
- ✅ Simple to implement and debug
- ✅ No external dependencies (Redis/RabbitMQ)
- ✅ Fast (no network overhead)
- ✅ Handles 1-50 symbols easily

When to upgrade to message queue:
- ❌ Analyzing 50+ symbols concurrently
- ❌ Need persistence across restarts
- ❌ Require distributed orchestrator instances

## Testing

### Unit Test Requirements
- Test each pipeline stage independently with mocked dependencies
- Test event bus publish/subscribe mechanism
- Test cache hit/miss scenarios
- Test error isolation: detector failure doesn't crash pipeline
- Test parallel symbol processing with asyncio.gather
- Test correlation_id propagation through all stages
- Test StageResult aggregation and error reporting

### Integration Test Requirements
- Load historical OHLCV data for known patterns
- Run full pipeline with real detectors
- Verify patterns detected match labeled dataset
- Verify signals generated have all required fields
- Measure end-to-end execution time
- Validate cache effectiveness (hit rate, performance improvement)

### Performance Test Requirements
- Generate 10 symbols × 500 bars of synthetic data
- Run analyze_symbols() concurrently
- Assert total time <5 seconds
- Measure per-stage timings
- Track cache hit rates
- Identify performance bottlenecks

[Source: architecture/12-testing-strategy.md]

## Wyckoff Team Review

### Review Date: 2025-01-21

### Reviewers

- **Richard (Wyckoff Mentor)**: Overall methodology review
- **Victoria (Volume Specialist)**: Volume analysis pipeline assessment
- **Rachel (Risk/Position Manager)**: Risk validation pipeline assessment

### Review Summary: APPROVED

The Master Orchestrator architecture correctly implements authentic Wyckoff methodology.

### Key Findings

| Area | Status | Reviewer |
|------|--------|----------|
| Pipeline sequencing (Data→Volume→Range→Phase→Pattern→Risk→Signal) | Approved | Richard |
| Volume analysis sequence (ratio→spread→close→effort/result) | Approved | Victoria |
| Volume requirements in pattern detection (FR12) | Approved | Victoria |
| Phase volume integration | Approved | Victoria |
| Risk validation sequence | Approved | Rachel |
| Risk-first signal generation | Approved | Rachel |
| Portfolio context completeness | Approved | Rachel |
| Performance targets | Achievable | Rachel |

### Enhancements Added

1. **VolumeAnalyzedEvent Enhancement** (Victoria)
   - Added `close_position` field (0.0-1.0 position within bar)
   - Added `effort_result` field (harmony/divergence classification)
   - Reduces downstream detector re-computation

2. **Rejection Categorization Enhancement** (Rachel)
   - Added task for rejection stage tracking
   - Near-miss analysis for threshold vs actual values
   - Campaign-level rejection aggregation for learning

### Wyckoff Authenticity Verification

| Principle | Implementation | Status |
|-----------|----------------|--------|
| Three Laws | Volume (Law 3) analyzed separately, integrated into pattern detection | Verified |
| Phase Progression | A→B→C→D→E enforced in Stage 4 | Verified |
| Volume-Price Harmony | Effort/result classification feeds pattern detection | Verified |
| Structural Risk | RiskManager uses Wyckoff levels, not arbitrary percentages | Verified |
| Campaign Thinking | Portfolio context includes active campaigns | Verified |

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-21 | 1.1 | Added Wyckoff team review enhancements | Richard (Wyckoff Mentor) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

- All tests pass: 89 tests (70 unit + 19 integration) in ~5.5 seconds
- Performance benchmark: 10 symbols × 500 bars completes in <5 seconds
- Mypy type checking: 0 errors with --strict
- Ruff linting: 0 errors

### Completion Notes

Story 8.1 implements the Master Orchestrator Architecture with a 7-stage pipeline:
1. Data → Volume → Range → Phase → Pattern → Risk → Signal
2. Event-driven coordination via in-memory EventBus
3. Dependency injection via OrchestratorContainer (supports mock mode for testing)
4. TTL-based LRU caching via OrchestratorCache (cachetools library)
5. Error isolation with circuit breaker pattern
6. Parallel symbol processing with asyncio.gather and semaphore
7. Structured logging with correlation IDs throughout

All 10 acceptance criteria have been met and tested.

### File List

**Created Files:**

- `backend/src/orchestrator/__init__.py` - Module exports
- `backend/src/orchestrator/master_orchestrator.py` - Core orchestrator class
- `backend/src/orchestrator/event_bus.py` - In-memory event bus
- `backend/src/orchestrator/events.py` - Event models (BarIngested, VolumeAnalyzed, etc.)
- `backend/src/orchestrator/container.py` - Dependency injection container
- `backend/src/orchestrator/pipeline_stage.py` - Pipeline stage abstraction
- `backend/src/orchestrator/cache.py` - TTL-based LRU caching
- `backend/src/orchestrator/config.py` - Orchestrator configuration
- `backend/src/orchestrator/service.py` - FastAPI service integration
- `backend/src/api/routes/orchestrator.py` - Health check and analysis endpoints
- `backend/tests/unit/orchestrator/test_event_bus.py` - Event bus unit tests
- `backend/tests/unit/orchestrator/test_cache.py` - Cache unit tests
- `backend/tests/unit/orchestrator/test_pipeline_stage.py` - Pipeline stage unit tests
- `backend/tests/unit/orchestrator/test_master_orchestrator.py` - Orchestrator unit tests
- `backend/tests/integration/orchestrator/test_full_pipeline.py` - Integration tests
- `backend/tests/integration/orchestrator/test_performance.py` - Performance benchmarks

**Modified Files:**

- `backend/src/api/main.py` - Added orchestrator routes and health check
- `backend/src/orchestrator/__init__.py` - Added service exports
- `backend/pyproject.toml` - Added cachetools dependency

## QA Results

_To be filled by QA Agent_
